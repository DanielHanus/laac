---
title: "tbd..."
author: "tbd..."
subtitle: Supplementary material
output:
  bookdown::pdf_document2:
    toc: yes
    number_sections: no
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    fig_caption: yes
    code_folding: hide
    number_sections: no
  html_document:
    toc: yes
    df_print: paged
  pdf_document:
    toc: yes
bibliography: ../library.bib
csl: apa6.csl
header-includes: \usepackage{caption} \renewcommand{\thetable}{S\arabic{table}} \renewcommand{\thefigure}{S\arabic{figure}}
---

```{r, include = F}
knitr::opts_chunk$set(echo=F, warning=FALSE, message=FALSE, size="small")
```


```{r, cache = F, include = F}
library(png)
library(grid)
library(xtable)
library(tidyverse)
library(tidybayes)
library(ggridges)
library(glue)
library(brms)
library(stringr)
library(forcats)
library(ggthemes)
library(ggpubr)
library(reshape)
library(ggExtra)
library(tidyboot)

source("../../utils/custom_facet.R")

cor_func <- function(x) {
  x %>%
    corrr::correlate()%>%
    gather(time_point, cor, -rowname)%>%
    mutate(cor = replace(cor, duplicated(cor), NA))%>%
    drop_na(cor)
}

library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
```

```{r}
# read in data files
## phase 1

p1_data_task <- read.csv("../../data/laac_data_task_phase1.csv") 
p1_data_trial <- read.csv("../../data/laac_data_trial_phase1.csv") 

data_task <- bind_rows(
  p1_data_task
)

data_trial <- bind_rows(
  p1_data_trial
)

```

# Overview

... Next we describe the different [tasks](#tasks) we sused ...

tasks - stability, reliability

predictors - predictability 

# Methods

## Participants

```{r}
participants <- data_trial%>%
  mutate(group = as.character(group), 
         species = ifelse(grepl("chimp",group),"chimpanzee", group), 
         species = factor(species))%>%
  group_by(species)%>%
  mutate(minage = round(min(age),1),
         maxage = round(max(age),1))%>%
  group_by(species, sex, minage,maxage)%>%
  summarise(n = length(unique(subject)))
  
  
 tpn <- data_trial%>%
     mutate(group = as.character(group), 
         species = ifelse(grepl("chimp",group),"chimpanzee", group), 
         species = factor(species))%>%
   group_by(time_point)%>%
   mutate(min_date = min(date))%>%
   group_by(time_point,species,.drop=FALSE)%>%
  summarise(n = length(unique(subject)),
            date = min(min_date))%>%
  group_by(time_point)%>%
  mutate(total_n = sum(n),
         date = as.Date(as.character(min(date)), "%Y%m%d"))%>%
   group_by(species)%>%
   mutate(end = date, 
          start = lag(as.character(end)))%>%
   mutate(start = ifelse(is.na(start),"2020-08-01",start),
          start = as.Date(start, format = "%Y-%m-%d"))%>%
   group_by(time_point)%>%
   mutate(shade = time_point %% 2 == 0)
   
```
A total of `r sum(participants$n)` great apes participated at least once in one of the tasks. This included `r participants%>%filter(species == "bonobo")%>%pull(n)%>%sum()` Bonobos (`r participants%>%filter(species == "bonobo", sex == "f")%>%pull(n)` females, age `r participants%>%filter(species == "bonobo", sex == "f")%>%pull(minage)` to `r participants%>%filter(species == "bonobo", sex == "f")%>%pull(maxage)`), `r participants%>%filter(species == "chimpanzee")%>%pull(n)%>%sum()` Chimpanzees (`r participants%>%filter(species == "chimpanzee", sex == "f")%>%pull(n)` females, age `r participants%>%filter(species == "chimpanzee", sex == "f")%>%pull(minage)` to `r participants%>%filter(species == "chimpanzee", sex == "f")%>%pull(maxage)`), `r participants%>%filter(species == "gorilla")%>%pull(n)%>%sum()` Gorillas (`r participants%>%filter(species == "gorilla", sex == "f")%>%pull(n)` females, age `r participants%>%filter(species == "gorilla", sex == "f")%>%pull(minage)` to `r participants%>%filter(species == "gorilla", sex == "f")%>%pull(maxage)`), and `r participants%>%filter(species == "gorilla")%>%pull(n)%>%sum()` Orangutans (`r participants%>%filter(species == "orangutan", sex == "f")%>%pull(n)` females, age `r participants%>%filter(species == "orangutan", sex == "f")%>%pull(minage)` to `r participants%>%filter(species == "orangutan", sex == "f")%>%pull(maxage)`). The sample size at the different time points ranged from `r min(tpn$n)` to `r max(tpn$n)`. Figure \@ref(fig:sample) visualizes the sample size across time points. We tried to test all apes at all time points but this was not always possible due to a lack of motivation or construction works. All apes participate in cognitive research on a regular basis. Many of them have ample experience with the very tasks we used in the current study.

Apes were housed at the Wolfgang Köhler Primate Research Center located in Zoo Leipzig, Germany. They lived in groups, with one group per species and two chimpanzee groups. Research was noninvasive and strictly adhered to the legal requirements in Germany. Animal husbandry and research complied with the European Association of Zoos and Aquaria Minimum Standards for the Accommodation and Care of Animals in Zoos and Aquaria as well as the World Association of Zoos and Aquariums Ethical Guidelines for the Conduct of Research on Animals by Zoos and Aquariums. Participation was voluntary, all food was given in addition to the daily diet, and water was available ad libitum throughout the study. The study was approved by an internal ethics committee at the Max Planck Institute for Evolutionary Anthropology.

```{r sample, out.width="100%", fig.height = 3, fig.cap = "Sample size by species across the different time points. Time point specific predictor variables were collected during the time between two time points (shaded regions) to predict the next."}

cols <- c(ptol_pal()(4),"black")

ggplot(tpn, aes(x = date, y = n, col = species))+
  geom_rect(aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf, fill= shade), col = NA, alpha =.1)+
  geom_rect(aes(xmin = as.Date("2020-08-01"), xmax = as.Date("2021-03-05"), ymin = 0, ymax = 40),fill = NA, col = "darkgrey")+
  annotate(geom="text", x=as.Date("2020-11-14"), y=42, label="Phase 1", color="black", size=4)+
  geom_point(alpha = .6)+
  geom_line(alpha = .6)+
  geom_point(aes(y = total_n), col = "black", alpha = .6)+
  geom_line(aes(y = total_n), col = "black", alpha = .6)+
  theme_minimal()+
  ylim(0,42)+
  labs(y = "Sample Size", x = "")+
  scale_color_manual(name = "Species", 
                   limits = c("bonobo", "chimpanzee", "gorilla", "orangutan", "total"),
                   labels =c("bonobo", "chimpanzee", "gorilla", "orangutan", "total"),
                   values = cols)+
  scale_x_date(date_breaks = "1 month",
             date_labels = "%b")+
  scale_fill_manual(values = c("grey", NA))+
  guides(fill = F)
```
## Setup

Apes were tested in familiar sleeping or observation rooms by a single experimenter. Whenever possible, they were tested individually.  The basic setup comprised a sliding table positioned in front of a clear Plexiglas panel with three holes in it. The experimenter sat on a small stool and used an occluder to cover the sliding table (see Figure \@ref(fig:setup)).

```{r setup, include = T, fig.cap = "Setup used for the six tasks. A) Causal reasoning and inference by exclusion. B) Quantity discrimination. C) Gaze following. D) Switching. E) Delay of gratification.", out.width="100%"}
knitr::include_graphics("figures/setup.png")
```

## Tasks

The tasks we selected are based on published procedures and are commonly used in the field of comparative psychology. The original publications often include control conditions to rule out alternative, non-cognitive explanations. We did not include such controls here and only ran the experimental conditions. For each task, we refer to the publication we used to model our procedure. We ask the reader to read these papers if they want to know more about control conditions and/or a detailed discussion of the nature of the underlying cognitive mechanisms.

Example videos for each task can be found in the associated online repository in [`videos/`](https://github.com/ccp-eva/laac/tree/master/videos).

### Causal inference

The causal inference task was modeled after @call2004inferences. Two identical cups with a lid were placed left and right on the table (Figure \@ref(fig:setup)A). The experimenter covered the table with the occluder, retrieved a piece of food, showed it to the ape, and hid it in one the cups outside the participant’s view. Next, the experimenter removed the occluder, picked up the baited cup and shook it three times, which produced a rattling sound. Next, the cup was put back in place, the sliding table pushed forwards, and the participant made a choice by pointing to one of the cups. If they picked the baited cup, their choice was coded as correct, and they received the reward. If they chose the empty cup, they did not. Participants received 12 trials. The location if the food was counterbalanced; 6 times in the right cup and 6 times in the left. Causal inference trials were intermixed with inference by exclusion trials.

We assume that apes locate the food by reasoning that the food -- a solid object -- caused the rattling sound and must thus be in the shaken cup. 

### Inference by exclusion

Inference by exclusion trials were also modeled after @call2004inferences and followed a very similar procedure compared to causal inference trials. After covering the two cups with the occluder, the experimenter placed the food in one of the cups and covered both with the lid. Next, they removed the occluder, picked up the empty cup and shook it three times. In contrast to the causal inference trials, this did not produce any sound. The experimenter then pushed the sliding table forward and the participant made a choice by pointing to one of the cups. Correct choice was coded when the baited (non-shaken) cup was chosen. If correct, the food was given to the ape. There were 12 inference by exclusion trials, intermixed with causal inference trials. The order was counterbalanced: 6 times the left cup was baited, 6 times the right. 

We assume that apes reason that the absence of a sound suggests that the shaken cup is empty. Because they saw a piece of food being hidden, they exclude the empty cup and infer that the food is more likely to be in the non-shaken cup. 

### Gaze Following

The gaze following task was modeled after @brauer2005all. The experimenter sat opposite the ape and handed over food at a constant pace. That is, the experimenter picked up a piece of food, briefly held it out in front of her face and then handed it over to the participant. After a predetermined (but varying) number of food items had been handed over, the experimenter again picked up a food item, held it in front of her face and then looked up (i.e., moving her head up - see Figure \@ref(fig:setup)C). The experimenter looked to the ceiling, no object of particular interest was placed there. After 10s, the experimenter looked down again, always handed over the food and the trial ended. We coded whether the participant looked up during the 10s interval.

We assume that participants look up in order to follow the experimenter's gaze to locate a potentially noteworthy object. 

### Quantity discrimination

For this task, we followed the general procedure of @hanus2007discrete. Two small plates were presented left and right on the table (see Figure \@ref(fig:setup)B). The experimenter covered the plates with the occluder and placed 5 small food pieces on one plate and 7 on the other. Then they pushed the sliding table forwards, and the participant made a choice. We coded as correct when the subject chose the plate with the larger quantity. Participants always received the food from the plate they chose. There were 12 trials, 6 with the larger quantity on the right and 6 on the left (order counterbalanced).

We assume that ??? 


### Switching

This task was modeled after @haun2006evolutionary. Three differently looking cups (metal cup with handle, red plastic ice cone, red cup without handle - Figure \@ref(fig:setup)D) were placed next to each other on the table. There were two conditions. In the place condition, the experimenter hid a piece of food under one of the cups in full view of the participant. Next, the cups were covered by the occluder and the experimenter switched the position of two cups, while the reward remained in the same location. Next, the experimenter removed the occluder and pushed the table forward. We coded as correct if the participant chose the location where the food was hidden. Participants received four trials in this condition. 

The place condition was run first. The feature condition followed the same procedure, but now the experimenter also moved the reward when switching the cups. The switch between conditions happened without informing the participant in any way. A correct choice in this condition meant choosing the location to which the cup plus the food were moved. Here, participants received eight trials. 

The dependent measure of interest for this task was calculated as: `[proportion correct place] - (1 - [proportion correct feature])`.  Positive values in this score mean that participants could quickly switch from choosing based on location to choosing based on feature. High negative values suggest that participants did not or hardly switch strategies.  

Based on the results of @haun2006evolutionary, we assume that apes have a tendency to expect the food to remain in the same location. When this strategy is no longer successful in the feature trials, they have to switch strategies and try a different one. 

### Delay of gratification

The procedure for this task was adapted from @rosati2007evolutionary. Two small plates including one and two pieces of pellet were presented left and right on the table. E moved the plate with the smaller reward forward allowing the subject to choose immediately, while the plate with the larger reward was moved forward after a delay of 20 seconds. We coded whether the subject selected the larger delayed reward (correct choice) or the smaller immediate reward (incorrect choice) as well as the waiting time in cases where the immediate reward was chosen. Subjects received 12 trials, with the side on which the immediate reward was presented counterbalanced. 


## Data collection

One time point meant running all tasks with all participants. Within each time point, the tasks were organized in two sessions (see Figure \@ref(fig:setup)F). Session 1 started with 2 gaze following trials. Next was a pseudo random mix of causal inference and inference by exclusion with 12 trials per task but no more than two trials of the same task in a row. At the end of session 1, there were again 2 gaze following trials. Sessions 2 also started with 2 gaze following trials, followed by quantity discrimination and switching. Finally, there were again 2 gaze following trials. B spreading out or mixing tasks we hoped to keep subjects more attentive and engaged. 

The order of tasks was the same for all subjects. So was the positioning of food items within each task. The counterbalancing can be found in the coding sheets in the online repository in `documentation/` [**to be added**]. This exact procedure was repeated at each time point so that the results would be comparable across participants. The two sessions were usually spread out across two adjacent days. For the larger chimpanzee group, they were sometimes spread out across 4 days. 

The interval between two time points was planned to be two weeks. However, it was not always possible to follow this schedule so that that some intervals are longer/shorter. Figure \@ref(fig:sample) visualizes the intervals between time points. 

We collected data in two phases. Phase 1 started on August 1st, 2020, lasted until March 5th, 2021 and included 14 time points (see Figure \@ref(fig:sample)). Phase 2 started on , lasted until and had time points.

## Predictors

In addition to the data from the cognitive tasks, we collected data for a range of predictor variables. The goal here was to find variables that are systematically related to inter- and/or intra-individual variation in cognitive performance. That is, we were interested to see which variables allow us to predict cognitive performance. The second part of the [analysis](#projection-predictive-inference) section, describes the method we used to determine the predictive value of each variable.    

Predictors could either vary with the individual (stable individual characteristics; e.g. sex or rearing history), vary with individual and time point (variable individual characteristics; e.g. sickness or sociality), vary with group membership (group life; e.g. time spent outdoors or disturbances) or vary with the testing arrangements (testing arrangements; e.g. presence of an observer or participation in other tests).

Most predictors were collected via a diary that the animal caretakers filled out on a daily basis. Here, the caretakers were asked a range of questions about the presence of a predictor and its severity. The diary (in German) can be found in `documentation/` in the associated online repository.

### Stable individual characteristics

These predictors are stable individual differences. As a source, we used the ape handbook at Zoo Leipzig. Figure \@ref(fig:demo) gives an overview of the distribution of the different characteristics in the sample. 

#### Age

Absolute age of the individual. For some older individuals, only the year of birth was known. In these cases we calculated age with January 1st of that year as the birthday.

#### Sex 

Participant's biological sex.

#### Rearing history

Here, we differentiated between, `mother-reared`, `hand-reared` and `unknown`. The last category was used only for three chimpanzees. In the analysis, we classified them as `hand-reared` to facilitate model fitting (i.e. it is very difficult to estimate a parameter for a factor level with so little data). We think this decision is justified because the individuals in question have spent most of their life in close contact to humans and not in a larger chimpanzee group. 

#### Time lived in Leipzig

Absolute time the individual has lived in Leipzig Zoo. All apes living in Leipzig are involved in behavioral research. Thus, we take this measure to be a rough proxy of how much experience an individual has had with cognitive research. 

```{r}
psex <- data_trial%>%
     mutate(group = as.character(group), 
         species = ifelse(grepl("chimp",group),"chimpanzee", group), 
         species = factor(species))%>%
  group_by(species, sex)%>%
  summarise(Frequency = length(unique(subject)))%>%
  ggplot(aes(x = species, y = Frequency, fill = sex))+
  geom_histogram(stat = "identity", position = position_dodge(), col = "black")+
  theme_minimal(base_size = 8)+
  scale_fill_grey(name = "Sex")+
  theme(legend.position = c(0.8,0.7), legend.key.size = unit(0.3, "cm"))+
  coord_flip()

prearing <- data_trial%>%
     mutate(group = as.character(group), 
         species = ifelse(grepl("chimp",group),"chimpanzee", group), 
         species = factor(species))%>%
  group_by(species, rearing,.drop=FALSE)%>%
  summarise(Frequency = length(unique(subject)))%>%
  ggplot(aes(x = species, y = Frequency, fill = rearing))+
  geom_histogram(stat = "identity", position = position_dodge(), col = "black")+
  theme_minimal(base_size = 8)+
  scale_fill_viridis_d(name = "Rearing history")+
  theme(legend.position = c(0.8,0.7), legend.key.size = unit(0.3, "cm"))+
  coord_flip()

page <- data_trial%>%
     mutate(group = as.character(group), 
         species = ifelse(grepl("chimp",group),"chimpanzee", group), 
         species = factor(species))%>%
  group_by(species, subject)%>%
  summarise(age = min(age))%>%
  ggplot(aes(x = age, y = species, fill = species))+
  geom_jitter(aes( col = species),alpha = .75, height = 0, width = .05, pch = "|", size = 5)+
  geom_density_ridges(col = "black", alpha = .5)+
  theme_minimal(base_size = 8)+
  scale_fill_ptol(name = "Species")+
  scale_color_ptol(name = "Species")+
  guides(fill = F, col = F)

pleipzig <- data_trial%>%
     mutate(group = as.character(group), 
         species = ifelse(grepl("chimp",group),"chimpanzee", group), 
         species = factor(species))%>%
  group_by(species, subject)%>%
  summarise(time_in_leipzig = min(time_in_leipzig))%>%
  ggplot(aes(x = time_in_leipzig, y = species, fill = species))+
  geom_jitter(aes( col = species),alpha = .75, height = 0, width = .05, pch = "|", size = 5)+
  geom_density_ridges(col = "black", alpha = .5)+
  theme_minimal(base_size = 8)+
  scale_fill_ptol(name = "Species")+
  scale_color_ptol(name = "Species")+
  guides(fill = F, col = F)
  
```

```{r demo, out.width="100%", fig.height = 4, fig.cap = "Stable individual characteristics. A) participant sex, B) age distribution by species, C) rearing history, D) time lived in leipzig by species."}

ggarrange(psex, page, prearing, pleipzig, nrow = 2, ncol= 2, widths = c(1,2), labels = c("A","B","C","D"))
```

### Variable individual characteristics

These predictors varied by participant and time point.

#### Rank

We asked caretakers to order individuals within a given group for their rank. Ties were allowed. This was done at each time point. An individual's rank was mostly stable (see Figure \@ref(fig:socrel)A) across time points, however, there was some variation. 

#### Sickness

As part of the caretakers' daily diary, we asked whether an individual was sick and if yes, how severe the sickness was on a scale from 1 to 7. For each time point, we used the mean of the daily sickness ratings as predictor.  

#### Sociality

```{r}
# ## get date ranges for each time point
# raw_data_date <- p1_data_trial %>%
#   mutate(date = ifelse(group == "b_chimp" & time_point == "13" & date == "20210203", "20210223", date))%>%
#   mutate(date = as.Date(as.character(date), format="%Y%m%d"))%>%
#   select(date, time_point,group)%>%
#   group_by(group,time_point)%>%
#   summarise(end_date = min(date))%>%
#   mutate(time_point = as.numeric(time_point))%>%
#   dplyr::arrange(group,-time_point)%>%
#   mutate(start_date = ifelse(time_point == 1, as.character(as.Date("2020-08-01", format="%Y-%m-%d")), as.character(end_date[-1])))%>%
#   #mutate(dif = time_length(interval(start_date, end_date), "days"))
#   mutate(end_date = as.Date(end_date-1, format = "%Y-%m-%d"),
#          start_date = as.Date(start_date, format = "%Y-%m-%d"),
#          time_point = factor(time_point))%>%
#   group_by(time_point, group)%>%
#   summarise(date = seq(start_date, end_date, by = "days"))%>%
#   dplyr::rename(species = group)%>%
#   mutate(species = paste(str_replace(species,"_","-"),"s",sep =""))
# 
# ## get a list of all possible dyady for all possible time points
# dyads <- list.files(path = "../../data/social_network_data",
#                        pattern = "*.csv",
#                        full.names = T)%>%
#   map_df(~read_csv(.))%>%
#   mutate(species = tolower(str_remove(`Configuration Name`, "LAAC ")),
#          session = SessionID,
#          date = as.Date(substr(as.character(DateTime),0,10),format="%Y-%m-%d"),
#          focal = `Focal Name`,
#          associates = `All Occurrence Behavior Social Modifier`)%>%
#   #filter(date2 != "2020-08-21")%>%
#   transform(associates = strsplit(associates,","))%>%
#   unnest(associates)%>%
#   select(species,focal,associates)%>%
#   gather(type, focal, -species)%>%
#   filter(!is.na(focal))%>%
#   distinct(species, focal)%>%
#   mutate(associates = focal)%>%
#   group_by(species)%>%
#   tidyr::expand(focal,associates,c(1:14))%>%
#   mutate(time_point = factor(`c(1:14)`))%>%
#   select(-`c(1:14)`)%>%
#   filter(focal != associates)
# 
# ## read in the data from the observational scans
# obs_data <- list.files(path = "../../data/social_network_data",
#                        pattern = "*.csv",
#                        full.names = T)%>%
#   map_df(~read_csv(.))%>%
#   mutate(species = tolower(str_remove(`Configuration Name`, "LAAC ")),
#          session = SessionID,
#          date = as.Date(substr(as.character(DateTime),0,10),format="%Y-%m-%d"),
#          focal = `Focal Name`,
#          associates = `All Occurrence Behavior Social Modifier`)%>%
#   #filter(date2 != "2020-08-21")%>%
#   transform(associates = strsplit(associates,","))%>%
#   unnest(associates)%>%
#   select(species,session,date, focal,associates)%>%
#   left_join(raw_data_date)%>%
#   group_by(species,time_point)%>%
#   mutate(n = length(unique(date)))%>% #compute the number of observations
#   group_by(species,focal, associates,time_point)%>%
#   summarise(count = n(), # count how often a combination of focal and associate occurred for a time point
#             n = max(n))%>%# include the number of observations for that time point
#   mutate(count = ifelse(is.na(associates),0,count))%>%
#   rowwise() %>%
#   filter(!is.na(associates))%>% # remove rows without associates
#   ungroup()
#   
# ## merge scan data with the dyads
# raw_srm_data <- dyads %>%
#   left_join(obs_data)%>%
#   group_by(species, time_point)%>%
#   mutate(n = max(n, na.rm = T))%>%
#   filter(n != "-Inf")%>%
#   mutate(count = ifelse(is.na(count),0,count))%>%
#   rowwise() %>%
#   mutate(dyad = paste(sort(c(focal, associates)), collapse = "_"))%>% # create ordered dyad column
#   ungroup()
# 
# ## prepare data for model run
# srm_model_data <- raw_srm_data%>%
#   group_by(time_point)%>%
#   distinct(dyad, .keep_all = T)%>% # remove duplicate dyads to avoid counting same dyad twice
#   ungroup()%>%
#   filter(!count > n) # remove rows with more counts than observations
# 
# ## run social relations model
# 
# ### specify priors
# prior <-  c(prior(normal(0,2), class = Intercept),
#             prior(normal(0,2), class = b),
#             prior(normal(0,1), class = sd)
#             )
# 
# ### run model 
# srm <-  brm(count | trials(n) ~ species + (0 + time_point | mm(focal, associates)) + ( 0 + time_point | dyad),
#            family = binomial(link = "logit"),
#            data = srm_model_data,
#            prior = prior,
#            #control = list(adapt_delta = 0.95, max_treedepth = 20),
#            iter = 5000, cores = 4, chains = 4)
# 
# ### save output 
# saveRDS(srm, "./saves/srm.rds")
# 
# ### load model results(too large to put on GitHub)
# srm <-  readRDS("./saves/srm.rds")
# 
# 
# ### get species infor for each subject
# subject_data <-  raw_srm_data%>%
#   ungroup()%>%
#   select(species, focal, associates)%>%
#   gather(role, subject,-species)%>%
#   distinct(subject, .keep_all = T)%>%
#   select(-role)%>%
#   arrange(species)%>%
#   mutate(subject = tolower(subject))%>%
#   mutate_at(.vars = vars(ends_with("s")),
#             .funs = funs(sub("s", "", .)))%>%
#   mutate(species = str_replace(species, "-", "_"))
# 
# ## extract model estimates for each subject 
# subject_draws <-  spread_draws(srm, r_mmfocalassociates[subject,time_point])%>% # extract posterior draws for each subject and time point
#   dplyr::rename(estimate = r_mmfocalassociates)%>%
#   mutate(subject = tolower(subject))%>% 
#   left_join(subject_data) # merge with subject information to get species in
# 
# ## summaries subject draws to put on GitHub
# subject_estimates <- subject_draws%>%
#   ungroup()%>%
#   mutate(time_point = as.numeric(str_remove(time_point, "time_point")))%>%
#   group_by(species, subject,time_point)%>%
#   summarise(mean = estimate_mode(estimate),
#             uci = hdi_upper(estimate),
#             lci = hdi_lower(estimate))
# 
# ## save subject draws to put on GitHub
# write_csv(subject_estimates, "./saves/srm_estimates.csv")

subject_estimates <- read_csv("./saves/srm_estimates.csv")

## generate plot
plot_est <-  subject_estimates%>%
  ungroup()%>%
  mutate(species_order = as.numeric(as.factor(species)),
         subject = factor(subject),
         subject = reorder(subject, species_order))


psrm <- plot_est%>%
  filter(#species == "gorilla" | 
           species == "orangutan")%>%
ggplot(.,aes(y = mean, x = factor(time_point), col = subject)) +
  geom_point(alpha = .5)+
  #geom_pointrange(aes(y = mean, ymin = lci, ymax = uci), alpha = .5, position = position_dodge(width = .5))+
  geom_line(aes(group = subject),alpha = .5)+
  facet_grid(~species)+
  theme_minimal()+
  scale_color_viridis_d(name ="Subject")+
  labs(x = "Time point", y = "Sociality")
```

We conducted proximity scans for all groups in the early afternoon on every workday (Monday to Friday). That is, we expect 10 scans for each time point. For each individual, we recorded which individuals are within arms reach. Research assistants used a tablet to record their observations. 

To derive individual specific estimates of sociality for each time point, we fit a variant of a Social Relations Model [@snijders1999social] to the proximity data. These models allow estimating an individual specific sociality index while accounting for the dyadic nature of social interaction. Social relations model usually deal with directed behaviors (e.g. individual *i* is grooming individual *j*). Because the behavior we observed was symmetric, we cannot differentiate between the actor and receiver. @Kajokaite2020.08.04.235788 suggested to speak of a Multiple Membership Relations Model [see also @leckie2019multiple] in such a context, which simply estimates how likely likely an individual is to be observed in proximity to another individual. 

In `brms` syntax, our model had the following structure: `count | trials(n) ~ group + (time_point | mm(focal, associates)) + (time_point | dyad)`. The dependent variable `count | trials(n)` is the number of times a dyad has been observed (`count`) at a time point relative to the number of scans taken for that time point (`trials(n)`). The fixed effect `group` estimates group difference in sociality. The random effect `(time_point | mm(focal, associates))` estimates the sociality for each individual. In that, the multi-membership grouping term `mm(focal, associates)` captures the fact that the assignment of the two roles (focal and associate) is arbitrary in the context of a symmetric behavior. The random slope `time_point` (treated as a factor) allowed us to estimate sociality for each time point. Finally, the random effect `(time_point | dyad)` accounts for dyad composition; in some cases a particular dyad composition (e.g. mother and infant) might be sufficient to explain high levels of sociality in an individual.

For each individual and time point, we extracted the sociality estimates and used them to predict cognitive performance in the different tasks for that time point. Figure \@ref(fig:socrel)B visualizes the sociality measures for one group across the different time points.     

```{r, out.width="100%", fig.height = 4, fig.cap = "Stable individual characteristics. A) participant sex, B) age distribution by species, C) rearing history, D) time lived in leipzig by species."}
prank <- data_trial%>%
     mutate(group = as.character(group), 
         species = ifelse(grepl("chimp",group),"chimpanzee", group), 
         species = factor(species))%>%
  group_by(subject, species)%>%
  summarise(sd = sd(rank, na.rm = T))%>%
  ggplot(aes(x = sd, y = species, fill = species))+
  geom_jitter(aes(col = species), height = 0, width = .05, pch = "|", size = 5)+
  geom_density_ridges(alpha = .5, col = "black")+
  labs(x ="Variability in rank (sd)")+
  theme_minimal()+
  scale_fill_ptol()+
  scale_colour_ptol()+
  scale_x_continuous(limits = c(0, 3), oob = scales::squish)+
  guides(col = F, pch = F, fill =F)
```

```{r socrel, out.width="100%", fig.height = 2, fig.cap = "Variable individual characteristics. A) variability in rank (caretaker ratings) for each subject and species, B) sociality estimates for orangutans based on Multiple Membership Relations Model."}
ggarrange(prank,psrm, labels = c("A","B"), widths = c(1,1.3))
```

### Group life

This set of predictors varied by time point and group, but were the same for all individuals in that group. They were recorded in the animal caretaker diary. Figure \@ref(fig:glife) visualizes the different variables across time points. 

#### Time outdoors

Each day, the animal caretakers noted in the diary how many hours each group spent in the outdoor enclosure. To compute the predictor, we averaged across these values for each time point and group. 

#### Disturbances

The animal caretakers also noted down if there were any unusual disturbances for a particular group. Example were construction works in the building, heavy weather conditions or green-keeping activities. In addition, the caretakers rated how disturbing they judged these events to be on a scale from 1 to 7. For each time point, we calculated the mean of these ratings.

#### Life events

This variable captured whether there were any notable events within the group. Examples were fights in the group or the temporal removal of some individuals for medical procedures. Again, we asked the caretakers to rate the severity of these events and averaged across them.  


```{r}
plife <- data_trial%>%
  group_by(time_point,group)%>%
  summarise(time_outdoors = mean(time_outdoors),
            disturbance = mean(dist_mean),
            life_event = mean(le_mean))%>%
  pivot_longer(names_to = "measure", values_to = "value", cols = c(-group, -time_point))%>%
  ggplot(aes(x = time_point, y = value, col = group))+
  geom_point()+
  geom_line(aes(group = group))+
  facet_grid(measure~., scales = "free_y")+
  labs(x = "Time Point", y = "")+
  scale_color_ptol(name = "Group")+
  theme_minimal()
```

```{r glife, out.width="100%", fig.height = 3, fig.cap = "Variation in group life related measures across groups and time points."}
plife
```

### Testing arrangements

Testing arrangements varied between individuals, sessions and time points. The experimenter recorded them either based on their observations during testing or from the testing schedule which lists all studies along with their participants that take place on a particular day.  

#### Observer

We noted whether or not there was another animal in the same room or the room adjacent to the one the participant was in. 

#### Study on same day

This predictor recorded whether or not the participant had already participated in a different test on the same day. The experimenter took this information from the testing schedule. 

#### Studies since last time point

Here we counted in how many other studies the participant had taken part in since the last time they were tested in that particular task. The experimenter took this information from the testing schedule.  

# Analytical framework

We have two overarching questions. On the one hand, we are interested in the stability and the reliability of the individual tasks as as well as the relations between them. We used structural equation modeling [citation?] to address these questions. These models have been developed and are usually used with much larger sample sizes. Thus, we had to make a number of assumptions to be able to fit them to the kind of data that we have -- we lay out these assumptions in the text below. The Appendix includes simulations that show that these assumptions were justified. 

The second question was which predictors explain variability in cognitive performance. Here we wanted to see, which of the predictors we recorded were most important to predict performance over time. This is a variable selection problem (selecting a subset of important predictors from a larger pool) and we used Projection Prediction Inference for this [@piironen2018projective]. 

We did not include the switching task from phase 1 in this analysis. There were three main reasons for this. First, group level scores were constantly negative and performance in the feature trials always overlapped with chance. This suggests that, as a group, apes did not successfully switch strategies (see \@ref(fig:perfplot)). Second, the correlations between the different measurement time points were low, suggesting no systematic individual differences (see \@ref(fig:relplot)). Third, the dependent variable (i.e. the score calculated based on performance in the two phases) had a different level of measurement compared to the other tasks. That is, there was only a single score to represent at each time point. All other tasks had multiple trials. This was especially problematic in the context of structural equation modeling (see below). For these reasons we replaced the switching task with the delay of gratification task in phase 2.

## Structural equation modelling

Structural equation models can be used to assess latent variables (constructs) using one or more observed variables. These latent variables can be combined in a structural model that imputes relations between them. We used the data from each time point as observed variables to estimate a latent construct for each task. Due to the small sample size, we could not combine latent variables in a structured model or use predictors to explain individual differences in these latent variables. Instead, we assessed relations between tasks by simply correlating  latent variables with one another. 

We used SEM to estimate states (time varying) and traits (stable over time). In the present context one can think of traits as a stable psychological ability (e.g. ability to make causal inferences) and states as variable psychological condition (e.g. being attentive). Variation in performance on a given time point can then be partitioned into variance explained by the trait and variance explained by the state. Next we describe the model construction process in more detail.

For each task, two parallel test halves were build, corresponding to sum scores of half of the trials of the same time point per task. Trials were alternately assigned to the first and the second test half. For tasks with 12 trials per time point this procedure resulted in two test halves assuming 7 possible values (0 to 6 correctly solved trials), for tasks with 8 trials per time point, test halves could maximally assume 5 possible values (0 to 4 correctly solved trials). Not all categories were observed at all time points and so sometimes categories had to be collapsed (see descriptions below). The two test halves served as indicators for a common latent construct per time point, assuming parallel test halves (i.e., factor loadings set to 1 and assuming equal reliabilities). Due to only few observed categories, indicators were modeled as ordered categorical, using a probit link function. The models thereby correspond to Graded response models [citation?]. For model parsimony, to improve estimation accuracy (see simulation studies) and in order to test for latent mean differences across time, thresholds for all indicators were set equal across time (resulting in the assumption of strict measurement invariance) as well as across test halves.

### Models and coefficients

For each task, we constructed three different models which increased in complexity. We started with a Latent State Model (LSM), which estimates a latent state for each time point based on the two test halves. As such, it does not assume an underlying trait. Stability is only indirectly assessed via correlations between states. This model first and foremost served as a baseline to see if the data supports a SEM approach.

Second, we fit a Latent State Trait Model (LSTM). This model estimates time point specific states, but also a time-invariant trait. With this model, we can partition the variance in performance into stable (trait) and variable (state) components.  

Finally, we fit an LSTM model with autoregressive effects. In addition to the LSTM architecture, this model assumes that the states variance at one time point can be used to predict the state variance in the next time point.

#### Latent State models

Measurement equation for parcel $i$ at time point $t$:

\begin{equation}
Y_{it}= S_t + \epsilon_{it}
(\#eq:eq1)
\end{equation}

At each time point $t$, a latent state variable $S_t$, underlying the two observed indicators $Y_{1t}$ and $Y_{2t}$ is estimated. Latent state variables are allowed to freely correlate across time, with latent (measurement-error free) correlations serving as indirect indicators of stability across time. The model is depicted for 6 measurement time points in Figure \@ref(fig:lsgraph). 

```{r lsgraph, engine='tikz', fig.cap="Latent State model for two indicators and six measurement time points.", out.width = "100%", out.height="30%", fig.align='center'}

\usetikzlibrary{arrows} 
\usetikzlibrary{positioning} 
\usetikzlibrary{shapes} 
\usetikzlibrary{fit} 
\usetikzlibrary{backgrounds} 
\usetikzlibrary{calc}

\begin{tikzpicture}
        [manifest/.style={rectangle,draw=black!80,semithick,minimum width=1.5cm,inner sep=
4pt,text centered},
        latent/.style={ellipse,draw=black!80,thick,inner sep=2,text centered},
        on/.style={->,>=stealth',semithick},
        from/.style={<-,>=stealth',semithick},
        with1/.style={<->,>=stealth',semithick,bend left=30},
        with2/.style={<->,>=stealth',semithick,bend right=30},
        with3/.style={<->,>=stealth',semithick,bend left=50},]

% Latent Variables %
 \begin{scope}[node distance=1.5]
                \node[latent] (o1) at (0,0) {$S_{1}$};
                \node[latent] (o2) [below=of o1] {$S_{2}$};
                \node[latent] (o3) [below=of o2] {$S_{3}$};
                \node[latent] (o4) [below=of o3] {$S_{4}$};
                \node[latent] (o5) [below=of o4] {$S_{5}$};
                \node[latent] (o6) [below=of o5] {$S_{6}$};
\end{scope}
                                                             	                        
% Manifest % 
 \foreach \a in {1,...,6} {\node (y1\a) [right = 2 of o\a] (yhelp\a) {};}        
 \foreach \b in {1,...,6} {\node[manifest] [above = .05 of yhelp\b] (y1\b) {$Y_{1\b}$}
 	edge [from] node[above] {1} (o\b);}
 \foreach \c in {1,...,6} {\node[manifest] [below = .05 of yhelp\c] (y2\c) {$Y_{2\c}$}
 	edge [from] node[below] {$1$} (o\c);} 

% Fehler %
\foreach \a in {1,...,5} {\node (e1\a) [below right = .3 of y1\a] {}
	edge [on] (y1\a.south east);}
\foreach \b in {1,...,5} {\node (e2\b) [below right = .3 of y2\b] {}
	edge [on] (y2\b.south east);}

\node (e16) [below right = .3 of y16] {$\epsilon_{16}$}
	edge [on] (y16.south east);
\node (e26) [below right = .3 of y26] {$\epsilon_{26}$}
	edge [on] (y26.south east);

%correlations%
\foreach \a in {1,...,5} {
\draw[<->,>=stealth',semithick] (o\a) to [with2]
node[align=center,below,yshift= 0mm, pos=0.5] 
                      {}  (o6);}
\foreach \a in {1,...,4} {
\draw[<->,>=stealth',semithick] (o\a) to [with2]
node[align=center,below,yshift= 0mm, pos=0.5] 
                      {}  (o5);}
\foreach \a in {1,...,3} {
\draw[<->,>=stealth',semithick] (o\a) to [with2]
node[align=center,below,yshift= 0mm, pos=0.5] 
                      {}  (o4);}
\foreach \a in {1,...,2} {
\draw[<->,>=stealth',semithick] (o\a) to [with2]
node[align=center,below,yshift= 0mm, pos=0.5] 
                      {}  (o3);}      
\draw[<->,>=stealth',semithick] (o1) to [with2]
node[align=center,below,yshift= 0mm, pos=0.5] 
                      {}  (o2);                

\end{tikzpicture}

```

#### Latent State Trait (LST) models

Measurement equation for parcel $i$ at time point $t$:

\begin{equation}
Y_{it}= T+ S_t + \epsilon_{it}
(\#eq:eq2)
\end{equation}

where $T$ is a stable latent trait variable, $S_t$ captures time-specific deviations of the respective true score from the stable trait at time $t$, and $\epsilon_{it}$ is a measurement error variable, with $Var(\epsilon_{it})=1 ~~~\forall i,t$ (probit parameterization; Graded response model). The model is depicted for 6 measurement time points in Figure \@ref(fig:lstgraph).  


```{r lstgraph, engine='tikz', fig.cap="Latent State Trait model for two indicators and six measurement time points.", out.width = "100%", out.height="30%", fig.align='center'}

\usetikzlibrary{arrows} 
\usetikzlibrary{positioning} 
\usetikzlibrary{shapes} 
\usetikzlibrary{fit} 
\usetikzlibrary{backgrounds} 
\usetikzlibrary{calc}

\begin{tikzpicture}
        [manifest/.style={rectangle,draw=black!80,semithick,minimum width=1.5cm,inner sep=
4pt,text centered},
        latent/.style={ellipse,draw=black!80,thick,inner sep=2,text centered},
        on/.style={->,>=stealth',semithick},
        from/.style={<-,>=stealth',semithick},
        with1/.style={<->,>=stealth',semithick,bend left=30},
        with2/.style={<->,>=stealth',semithick,bend right=30},
        with3/.style={<->,>=stealth',semithick,bend left=50},]
        
% Latent Variables %
 \begin{scope}[node distance=1.5]
                \node[latent] (o1) at (0,0) {$S_{1}$};
                \node[latent] (o2) [below=of o1] {$S_{2}$};
                \node[latent] (o3) [below=of o2] {$S_{3}$};
                \node[latent] (o4) [below=of o3] {$S_{4}$};
                \node[latent] (o5) [below=of o4] {$S_{5}$};
                \node[latent] (o6) [below=of o5] {$S_{6}$};
\end{scope}
                     
% Trait % 
\node[latent,node distance=7] (t) [right=of  o4]  {$T_{}$};
                                             	                        
% Manifest % 
 \foreach \a in {1,...,6} {\node (y1\a) [right = 2 of o\a] (yhelp\a) {};}        
 \foreach \b in {1,...,6} {\node[manifest] [above = .05 of yhelp\b] (y1\b) {$Y_{1\b}$}
 	edge [from] node[above] {1} (o\b);}
 \foreach \c in {1,...,6} {\node[manifest] [below = .05 of yhelp\c] (y2\c) {$Y_{2\c}$}
 	edge [from] node[below] {$1$} (o\c);} 

% Fehler %
\foreach \a in {1,...,5} {\node (e1\a) [below right = .3 of y1\a] {}
	edge [on] (y1\a.south east);}
\foreach \b in {1,...,5} {\node (e2\b) [below right = .3 of y2\b] {}
	edge [on] (y2\b.south east);}

\node (e16) [below right = .3 of y16] {$\epsilon_{16}$}
	edge [on] (y16.south east);
\node (e26) [below right = .3 of y26] {$\epsilon_{26}$}
	edge [on] (y26.south east);

% Pfeile %
\foreach \a in {1,...,6}
	\path (y1\a.0) edge [from] (t);
\foreach \a in {1,...,6}	
	\path (y2\a.0) edge [from] (t);
\end{tikzpicture}

```

Note that by assuming strong measurement invariance (i.e., loading parameters are set to 1 at all time points, residual variances are equal to 1 by definition of the Graded response model with a probit link, threshold parameters are set invariant across time points, variances of latent state residual factors are set invariant across time points), the specified LST model (without autoregressive effects) corresponds to a multilevel model with a latent trait factor at the between-level (person-level) and a latent state residual factor at the within-level (time-specific) level.

In order to test for possible mean changes across time, latent state models are estimated in a first step. LST models as single-level models are estimated to test whether measurement invariance assumptions across time can be reasonably assumed. Once measurement invariance can be established, the models can alternatively estimated as multilevel SEMs.

The following variance components can be computed for the presented LST model (without autoregressive effects).

##### Consistency

Proportion of true variance (i.e., measurement-error free variance) that is due to true inter-individual stable trait differences.

\begin{equation}
Con(Y_{it})=\frac{Var(T)}{Var(T)+Var(S_t)}
(\#eq:eq3)
\end{equation}

##### Occasion specificity

Proportion of true variance (i.e., measurement-error free variance) that is due to true inter-individual differences in the state residual variables (i.e. occasion-specific variation not explained by the trait).

\begin{equation}
OS(Y_{it})=1-Con(Y_{it})) = \frac{Var(S_t)}{Var(T)+Var(S_t)}
(\#eq:eq4)
\end{equation}

As strong measurement invariance is assumed and $Var(S_t)$ is set equal across time, $OS(Y_{it})$ is constant across time as well as across item parcels $i$. 

#### Latent State Trait (LST) models with autoregressive effects

Model corresponds to model described in @eid2017definition. The model is depicted for 6 measurement time points in Figure \@ref(fig:lstrgraph).

```{r lstrgraph, engine='tikz', fig.cap="Latent State Trait model with autoregressive effects for two indicators and six measurement time points.", out.width = "100%", out.height="30%", fig.align='center'}

\usetikzlibrary{arrows} 
\usetikzlibrary{positioning} 
\usetikzlibrary{shapes} 
\usetikzlibrary{fit} 
\usetikzlibrary{backgrounds} 
\usetikzlibrary{calc}

\begin{tikzpicture}
 [manifest/.style={rectangle,draw=black!80,semithick,minimum width=1.5cm,inner sep=
4pt,text centered},
        latent/.style={ellipse,draw=black!80,thick,inner sep=2,text centered},
        on/.style={->,>=stealth',semithick},
        from/.style={<-,>=stealth',semithick},
        with1/.style={<->,>=stealth',semithick,bend left=30},
        with2/.style={<->,>=stealth',semithick,bend right=30},
        with3/.style={<->,>=stealth',semithick,bend left=50},]


% Latent Variables %
 \begin{scope}[node distance=1.5]
                \node[latent] (o1) at (0,0) {$S_{1}$};
                \node[latent] (o2) [below=of o1] {$O_{2}$}
                edge [from] node[right] {$\beta$} (o1);
                \node[latent] (o3) [below=of o2] {$O_{3}$}
                edge [from] node[right] {$\beta$} (o2);
                \node[latent] (o4) [below=of o3] {$O_{4}$}
                edge [from] node[right] {$\beta$} (o3);
                \node[latent] (o5) [below=of o4] {$O_{5}$}
                edge [from] node[right] {$\beta$} (o4);
                \node[latent] (o6) [below=of o5] {$O_{6}$}
                edge [from] node[right] {$\beta$} (o5);
\end{scope}

\foreach \a in {2,...,6} {\node [below left = .4 of o\a] (zeta\a) {$S_{\a}$}
	edge [on] (o\a);}
                     
% Trait % 
\node[latent,node distance=7] (t) [right=of  o4]  {$T_{}$};
                                             	                        
% Manifest % 
 \foreach \a in {1,...,6} {\node (y1\a) [right = 2 of o\a] (yhelp\a) {};}        
 \foreach \b in {1,...,6} {\node[manifest] [above = .05 of yhelp\b] (y1\b) {$Y_{1\b}$}
 	edge [from] node[above] {1} (o\b);}
 \foreach \c in {1,...,6} {\node[manifest] [below = .05 of yhelp\c] (y2\c) {$Y_{2\c}$}
 	edge [from] node[below] {$1$} (o\c);} 

% Fehler %
\foreach \a in {1,...,5} {\node (e1\a) [below right = .3 of y1\a] {}
	edge [on] (y1\a.south east);}
\foreach \b in {1,...,5} {\node (e2\b) [below right = .3 of y2\b] {}
	edge [on] (y2\b.south east);}

\node (e16) [below right = .3 of y16] {$\epsilon_{16}$}
	edge [on] (y16.south east);
\node (e26) [below right = .3 of y26] {$\epsilon_{26}$}
	edge [on] (y26.south east);

% Pfeile %
\foreach \a in {1,...,6}
	\path (y1\a.0) edge [from] (t);
\foreach \a in {1,...,6}	
	\path (y2\a.0) edge [from] (t);
\end{tikzpicture}

```

Measurement equation for parcel $i$ at time point $t$:

\begin{equation}
Y_{it}= T+ O_t + \epsilon_{it}
(\#eq:eq5)
\end{equation}

where $T$ is a stable latent trait variable, $O_t$ captures time-specific deviations of the respective true score from the stable trait at time $t$, and $\epsilon_{it}$ is a measurement error variable,  with $Var(\epsilon_{it})=1 ~~~\forall i,t$ (probit parameterization; Graded response model). $O_t$ is assumed to follow an autoregressive process of order 1 across time (within subjects), that is:

\begin{align}
O_t  &= S_t ~~~~~~~~t = 1 \notag \\
O_t  &= \beta O_{(t-1)} + S_t~~~~~~~~t > 1 \notag
\end{align}

where the latent state residual variables $S_t$ capture true occasion-specific inter-individual differences that cannot be explained by states at previous measurement time points.

The following variance coefficients can be computed.

##### Consistency

Proportion of true variance (i.e., measurement-error free variance) that is due to true inter-individual stable trait differences.

\begin{equation}
Con(Y_{it})=\frac{Var(T)}{Var(T)+\beta^2 Var(O_{(t-1)})+Var(S_t)}
(\#eq:eq6)
\end{equation}

##### Occasion specificity

Proportion of true variance (i.e., measurement-error free variance) that is due to true inter-individual differences in the state residual variables, that is occasion-specific variation that is not explained by the autoregressive process.

\begin{equation}
OS(Y_{it}) = \frac{Var(S_t)}{Var(T)+\beta^2 Var(O_{(t-1)})+Var(S_t)}
(\#eq:eq7)
\end{equation}

As the proportion of variance explained by the autoregressive process stabilizes over time, all coefficients have converged to a relatively stable value at $t=14$, indicating the long-term proportions of variance that are to be expected.

##### Predictability

Proportion of true variance that is explained by carry-over effects from previous measurement time points.

\begin{equation}
Pred(Y_{it}) = \frac{\beta^2 Var(O_{(t-1)}}{Var(T)+\beta^2 Var(O_{(t-1)})+Var(S_t)}
(\#eq:eq8)
\end{equation}

### Estimation

Models were estimated with MPlus version 8.4, using Bayesian Markov-Chain Monte-Carlo sampling, with the Mplus default priors (also see simulation studies). Using inverse gamma priors [IG(0.001, 0.001); see simulation study] for LST models did not substantially change the parameter estimates. Therefore, only the results with respect to the MPlus default priors are reported. We used two chains with a minimum of 10,000 iterations per chain, with a thinning of 10 (corresponds to a minimum of 100,000 drawn samples per chain of which every 10th is used for the construction of the posterior distribution). The first half of each chain is discarded as burn-in. Convergence was assumed and estimation stopped when the Potential Scale Reduction (PSR) factor well below a threshold of 1.01 for the first time after the minimum number of iterations was reached.










## Projection predictive inference

The predictive projection approach developed by @piironen2018projective was used to select a minimal subset of covariates to find a predictive model for cognitive performance. Projective selection can be viewed as a two-step process. The first step revolves around building the best predictive model possible, called the reference model. The reference model is a Bayesian multilevel regression model (repeated measurements nested in apes), including all covariates recorded in this study. In the second step, the goal is to replace the posterior distribution of the reference model with a simpler distribution. This is achieved via a forward stepwise addition of covariates that decrease the Kullback-Leibler divergence from the reference model to the projected model. The result is a list containing the best model for each number of covariates. The final model is selected by inspecting the mean log predictive density. The projected model with the smallest number of covariates shows similar predictive performance as the reference model is chosen.

The advantages of predictive projection are that it provides an excellent tradeoff between model complexity and accuracy @piironen2017comparison. It has also been shown that predictive projection is useful when identifying **all relevant** covariates is of importance. 

The predictive projection technique is implemented in the R package 'projpred' @projpred202.

We built a reference model for each task, resulting in four reference models and four rankings of relevant predictors. 

# Results

## Phase 1

### Descriptives

```{r, cache = T}
time_plot_1 <- data_task%>%
 filter(task != "switching_feature",
         task != "switching_place")%>%
  mutate(group = as.character(group), 
         species = ifelse(grepl("chimp",group),"chimpanzee", group), 
         species = factor(species))%>%
  drop_na(performance)%>%
  #mutate(time_point = factor(time_point))%>%
  group_by(task, time_point, species)%>%
  summarise(mean = mean(performance,na.rm = TRUE))

switch_data <- data_trial%>%
  filter(grepl("switch", task))%>%
  group_by(task, time_point)%>%
  tidyboot_mean(col = code, na.rm = TRUE)%>%
  mutate(phase = str_remove(task,"switching_"),
         task = "switching")

time_plot_2 <- data_task%>%
    filter(task != "switching_feature",
         task != "switching_place")%>%
  mutate(group = as.character(group), 
         species = ifelse(grepl("chimp",group),"chimpanzee", group), 
         species = factor(species))%>%
  drop_na(performance)%>%
  #mutate(time_point = factor(time_point))%>%
  group_by(task, time_point)%>%
  tidyboot_mean(col = performance, na.rm = TRUE)%>%
  mutate(n = n(),
         chance = ifelse(task == "switching", 1/3, ifelse(task == "gaze_following", NA,0.5)))
```

```{r}
# perfcaus <- ggplot()+
#   geom_hline(data = time_plot_2%>%filter(task == "causality"),aes(yintercept = chance), lty = 2, col = "black", alpha = .75)+
#   geom_point(data = time_plot_1%>%filter(task == "causality"), aes(x = time_point, y = mean,  col = species), alpha = .6)+
#   geom_line(data = time_plot_1%>%filter(task == "causality"), aes(x = time_point, y = mean, col = species, group = species), alpha = .6)+
#   geom_pointrange(data = time_plot_2%>%filter(task == "causality"), aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper),pch = 4)+
#   geom_line(data = time_plot_2%>%filter(task == "causality"), aes(x = time_point, y = mean, group = task))+
#   theme_minimal()+
#     geom_pointrange(data = switch_data%>%filter(task == "causality"), aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper, pch = phase), alpha = .5)+
#   labs(x = "", y = "")+
#   geom_line(data = switch_data%>%filter(task == "causality"), aes(x = time_point, y = mean, group = phase), alpha = .5)+
#   theme_minimal()+
#   ylim(0,1)+
#   guides(size = F)+
#   scale_shape(name = "Switching Phase")+
#   scale_color_ptol(name = "Species")
# 
# perfinf <- ggplot()+
#   geom_hline(data = time_plot_2%>%filter(task == "inference"),aes(yintercept = chance), lty = 2, col = "black", alpha = .75)+
#   geom_point(data = time_plot_1%>%filter(task == "inference"), aes(x = time_point, y = mean,  col = species), alpha = .6)+
#   geom_line(data = time_plot_1%>%filter(task == "inference"), aes(x = time_point, y = mean, col = species, group = species), alpha = .6)+
#   geom_pointrange(data = time_plot_2%>%filter(task == "inference"), aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper),pch = 4)+
#   geom_line(data = time_plot_2%>%filter(task == "inference"), aes(x = time_point, y = mean, group = task))+
#   theme_minimal()+
#     geom_pointrange(data = switch_data%>%filter(task == "inference"), aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper, pch = phase), alpha = .5)+
#   labs(x = "", y = "Performance")+
#   geom_line(data = switch_data%>%filter(task == "inference"), aes(x = time_point, y = mean, group = phase), alpha = .5)+
#   theme_minimal()+
#   ylim(0,1)+
#   guides(size = F)+
#   scale_shape(name = "Switching Phase")+
#   scale_color_ptol(name = "Species")
# 
# perfquant <- ggplot()+
#   geom_hline(data = time_plot_2%>%filter(task == "quantity"),aes(yintercept = chance), lty = 2, col = "black", alpha = .75)+
#   geom_point(data = time_plot_1%>%filter(task == "quantity"), aes(x = time_point, y = mean,  col = species), alpha = .6)+
#   geom_line(data = time_plot_1%>%filter(task == "quantity"), aes(x = time_point, y = mean, col = species, group = species), alpha = .6)+
#   geom_pointrange(data = time_plot_2%>%filter(task == "quantity"), aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper),pch = 4)+
#   geom_line(data = time_plot_2%>%filter(task == "quantity"), aes(x = time_point, y = mean, group = task))+
#   theme_minimal()+
#     geom_pointrange(data = switch_data%>%filter(task == "quantity"), aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper, pch = phase), alpha = .5)+
#   labs(x = "", y = "")+
#   geom_line(data = switch_data%>%filter(task == "quantity"), aes(x = time_point, y = mean, group = phase), alpha = .5)+
#   theme_minimal()+
#   ylim(0,1)+
#   guides(size = F)+
#   scale_shape(name = "Switching Phase")+
#   scale_color_ptol(name = "Species")
# 
# perfgaze <- ggplot()+
#   geom_hline(data = time_plot_2%>%filter(task == "gaze_following"),aes(yintercept = chance), lty = 2, col = "black", alpha = .75)+
#   geom_point(data = time_plot_1%>%filter(task == "gaze_following"), aes(x = time_point, y = mean,  col = species), alpha = .6)+
#   geom_line(data = time_plot_1%>%filter(task == "gaze_following"), aes(x = time_point, y = mean, col = species, group = species), alpha = .6)+
#   geom_pointrange(data = time_plot_2%>%filter(task == "gaze_following"), aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper),pch = 4)+
#   geom_line(data = time_plot_2%>%filter(task == "gaze_following"), aes(x = time_point, y = mean, group = task))+
#   theme_minimal()+
#     geom_pointrange(data = switch_data%>%filter(task == "gaze_following"), aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper, pch = phase), alpha = .5)+
#   labs(x = "", y = "")+
#   geom_line(data = switch_data%>%filter(task == "gaze_following"), aes(x = time_point, y = mean, group = phase), alpha = .5)+
#   theme_minimal()+
#   ylim(0,1)+
#   guides(size = F)+
#   scale_shape(name = "Switching Phase")+
#   scale_color_ptol(name = "Species")
# 
# perfswitch <- ggplot()+
#   geom_hline(data = time_plot_2%>%filter(task == "switching"),aes(yintercept = chance), lty = 2, col = "black", alpha = .75)+
#   geom_point(data = time_plot_1%>%filter(task == "switching"), aes(x = time_point, y = mean,  col = species), alpha = .6)+
#   geom_line(data = time_plot_1%>%filter(task == "switching"), aes(x = time_point, y = mean, col = species, group = species), alpha = .6)+
#   geom_pointrange(data = time_plot_2%>%filter(task == "switching"), aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper),pch = 4)+
#   geom_line(data = time_plot_2%>%filter(task == "switching"), aes(x = time_point, y = mean, group = task))+
#   theme_minimal()+
#     geom_pointrange(data = switch_data, aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper, pch = phase), alpha = .5)+
#   labs(x = "Time Point", y = "")+
#   geom_line(data = switch_data, aes(x = time_point, y = mean, group = phase), alpha = .5)+
#   theme_minimal()+
#   ylim(-1,1)+
#   guides(size = F)+
#   scale_shape(name = "Switching Phase")+
#   scale_color_ptol(name = "Species")

perfplot <- ggplot()+
  facet_wrap_custom(task~., scales = "free_y", ncol = 2, scale_overrides = list(
    scale_override(1, scale_y_continuous(limits = c(0, 1))),
    scale_override(2, scale_y_continuous(limits = c(0, 1))),
    scale_override(3, scale_y_continuous(limits = c(0, 1))),
    scale_override(4, scale_y_continuous(limits = c(0, 1))),
    scale_override(5, scale_y_continuous(limits = c(-1, 1)))
  ))+
  geom_hline(data = time_plot_2,aes(yintercept = chance), lty = 2, col = "black", alpha = .75)+
  geom_point(data = time_plot_1, aes(x = time_point, y = mean,  col = species), alpha = .6)+
  geom_line(data = time_plot_1, aes(x = time_point, y = mean, col = species, group = species), alpha = .6)+
  geom_pointrange(data = time_plot_2, aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper),pch = 4)+
  geom_line(data = time_plot_2, aes(x = time_point, y = mean, group = task))+
  theme_minimal()+
    geom_pointrange(data = switch_data, aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper, pch = phase), alpha = .5)+
  labs(x = "Time Point", y = "Performance")+
  geom_line(data = switch_data, aes(x = time_point, y = mean, group = phase), alpha = .5)+
  theme_minimal()+
  guides(size = F)+
  scale_shape(name = "Switching Phase")+
  scale_color_ptol(name = "Species")
```

```{r perfplot, fig.height=5, fig.cap = "Results from the five cognitive tasks across time points. Black crosses show mean performance at each time point across species (with 95\\% CI). Colored dots show mean performance by species. Dashed line shows the chance level whenever applicable. The panel for switching includes triangles and dots showing the mean performance in the two phases from which the overall performance score was computed.", out.width="100%"}
# ggarrange(perfcaus, perfcaus, perfquant, perfgaze, perfswitch, common.legend = T, ncol= 1,  labels = c("A","B","C","D","E"), legend = "right")

perfplot
```


```{r}
cor_data <- data_task %>%
  drop_na(performance)%>%
  select(subject, task, time_point, performance)%>%
  pivot_wider(values_from = "performance", names_from = "time_point")%>%
  ungroup()%>%
  select(-subject)%>%
  group_by(task)%>%
  group_split(.keep = F)%>%
  setNames(unique(data_task$task))%>%
  purrr::map(cor_func)%>%
  melt()%>%
  mutate(task = factor(L1))%>%
  filter(task != "switching_place",
         task != "switching_feature")

cor_data_sum <- cor_data%>%
  group_by(task)%>%
  mean_hdci(value)
  
# ggplot(cor_data, aes(x = value, col = task, fill = task))+
#   #geom_histogram(col = "black", fill = "white")+
#   geom_density(alpha = .3)+
#   #xlim(-0.5,1)+
#   #facet_wrap(~task)+
#   labs(x = "Correlation Coefficient", y = "")+
#   theme_minimal()+
#   scale_color_colorblind(name = "Task")+
#   scale_fill_colorblind(name = "Task")


rel_plot <- ggplot(data = cor_data, aes(x = value , y = reorder(task, desc(task)) ,fill = task)) +
  geom_vline(xintercept = 0, color = "black", size = .5, lty = 2) +
  geom_density_ridges(rel_min_height = 0.01,col = "black", scale = 2,
                      alpha = 0.5) +
  geom_pointintervalh(data = cor_data_sum, size = 1)+
  labs(x = "Correlation Coefficient",
       y = element_blank()) +
  geom_text(data = mutate_if(cor_data_sum, is.numeric, round, 1),
    aes(label = glue("{value} [{.lower}, {.upper}]"), x= Inf), hjust = "inward", size = 2)+
  theme_minimal(base_size = 8)+
  xlim(-0.5,1.5)+
  guides(fill = F)+
  scale_fill_colorblind()

rel_plot_dis <- cor_data%>%
  mutate(time_span = abs(as.numeric(rowname) - as.numeric(time_point)))%>%
  ggplot(aes(x = time_span, y = value, col = task))+
  geom_point(alpha = .5, size = 0.75)+
  geom_smooth(method = "lm", se = F, col = "black", lty = 2, size = .5)+
  stat_cor(method = "pearson", aes(x = time_span, y = value, label = paste(..r.label..)), inherit.aes = F, size = 2,r.accuracy = 0.01, cor.coef.name = "r")+
  ylim(0,1)+
  xlim(1,7)+
  labs(y = "Correlation Coefficient",
     x = "Time Span") +
  facet_grid(~task)+
  theme_minimal(base_size = 8)+
  guides (col = F)+
  scale_colour_colorblind()


```


```{r relplot, fig.env = "figure*", fig.pos = "h", fig.width=7, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "(A) Distribution of correlations between time points for each task. Dots represent the mean of the distribution with 95\\% HDI. Numbers denote mean and 95\\% HDI. (B) Correlations between re-test reliability and time span (in time points) between the testing time points."}
ggarrange(rel_plot, rel_plot_dis, widths = c(2,3), labels = c("A","B"), font.label = list(size = 10))
```

### Stability

### Reliability

- raw correlations over time 

### Relations between tasks

### Predictability

# Summary

# Appendix

## SEM Simulations



