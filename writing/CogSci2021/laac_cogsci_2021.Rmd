---
title: "How to Make a Proceedings Paper Submission"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Morton Ann Gernsbacher (MAG@Macc.Wisc.Edu)} \\ Department of Psychology, 1202 W. Johnson Street \\ Madison, WI 53706 USA
    \AND {\large \bf Sharon J.~Derry (SDJ@Macc.Wisc.Edu)} \\ Department of Educational Psychology, 1025 W. Johnson Street \\ Madison, WI 53706 USA}

abstract: >
    Include no author information in the initial submission, to facilitate
    blind review.  The abstract should be one paragraph, indented 1/8 inch on both sides,
    in 9~point font with single spacing. The heading 'Abstract'
    should be 10~point, bold, centered, with one line of space below
    it. This one-paragraph abstract section is required only for standard
    six page proceedings papers. Following the abstract should be a blank
    line, followed by the header 'Keywords' and a list of
    descriptive keywords separated by semicolons, all in 9~point font, as
    shown below.
    
keywords: >
    Add your choice of indexing terms or keywords; kindly use a semi-colon; between each term.
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r}
library(png)
library(grid)
library(xtable)
library(tidyverse)
library(tidybayes)
library(ggridges)
library(glue)
library(brms)
library(stringr)
library(forcats)
library(ggthemes)
library(ggpubr)
library(reshape)
library(tidyboot)

cor_func <- function(x) {
  x %>%
    corrr::correlate()%>%
    gather(time_point, cor, -rowname)%>%
    mutate(cor = replace(cor, duplicated(cor), NA))%>%
    drop_na(cor)
}
```

```{r}
raw_data <-  read_csv("cogsci_data_trial.csv")
data_task <-  read_csv("cogsci_data_task.csv")
```

# Introduction

Describe the first results of a long term project that focuses on the stability, reliability and predictability of cognitive performance in great apes. Thus, we ask how stable performance is on a group level, how reliable individual differences in performance are and to what extend these individual differences can be explained by a common set of predictor variables.   

Animal cognition studies are hardly ever replicated: Only 2 % of studies incldued a replicaiton in recent review. Unclear how stable results are. 

ManyPrimates et al. (2019) Collaborative open science as a way to reproducibility and new insights in primate cognition research. Japanese Psychological Review 62(3), 205-220

Farrar, B.G., Boeckle, M, Clayton N. S. Replications in Comparative Cognition: What Should We Expect and How Can We Improve? Animal Behavior and  Cognition 7 (1), 1-22 

Farrar, B. G., Voudouris, K., & Clayton, N. S. Replications, Comparisons, Sampling and the Problem of Representativeness in Animal Behavior and Cognition Research. Psyarxiv [pre-print]

Know very little about reliability of individual tasks. That is the stability of individual differences as opposed to group level means. Reliability is important to know for study design. If you want to realte measures to one another, they should have high reliability (the produt of re-test reliabilities is the upper limit of correlations to expect between tasks).

shifting vs switching

christoph paper - executive functioning und psychometrics paper

Researchers in animal cognition often wonder whether performance in cognitive tasks can be (in part) be explained by individual level characteristics such as age, sex, rank or rearing history. However, usually samples are too small to really disentangle theses effects. Furthermore, sometimes these characteristics are correlated. For example, in chimpanzees, higher ranking individuals are usually middle aged males. 

Five tasks that have been used before with a wide variety of species and that cover a road range of cognitive abilities. 

# Methods

## Participants
```{r}
participants <- raw_data%>%
  mutate(species = ifelse(grepl("chimp", group),"chimpanzee",group))%>%
  group_by(species)%>%
  mutate(minage = round(min(age),1),
         maxage = round(max(age),1))%>%
  group_by(species, sex, minage,maxage)%>%
  summarise(n = length(unique(subject)))
  
  
 tpn <- raw_data%>%
  group_by(time_point)%>%
  summarise(n = length(unique(subject)))
```
A total of `r sum(participants$n)` great apes participated at least once in one of the tasks. This included `r participants%>%filter(species == "bonobo")%>%pull(n)%>%sum()` Bonobos (`r participants%>%filter(species == "bonobo", sex == "f")%>%pull(n)` females, age `r participants%>%filter(species == "bonobo", sex == "f")%>%pull(minage)` to `r participants%>%filter(species == "bonobo", sex == "f")%>%pull(maxage)`), `r participants%>%filter(species == "chimpanzee")%>%pull(n)%>%sum()` Chimpanzees (`r participants%>%filter(species == "chimpanzee", sex == "f")%>%pull(n)` females, age `r participants%>%filter(species == "chimpanzee", sex == "f")%>%pull(minage)` to `r participants%>%filter(species == "chimpanzee", sex == "f")%>%pull(maxage)`), `r participants%>%filter(species == "gorilla")%>%pull(n)%>%sum()` Gorillas (`r participants%>%filter(species == "gorilla", sex == "f")%>%pull(n)` females, age `r participants%>%filter(species == "gorilla", sex == "f")%>%pull(minage)` to `r participants%>%filter(species == "gorilla", sex == "f")%>%pull(maxage)`) and , `r participants%>%filter(species == "gorilla")%>%pull(n)%>%sum()` Orangutans (`r participants%>%filter(species == "orangutan", sex == "f")%>%pull(n)` females, age `r participants%>%filter(species == "orangutan", sex == "f")%>%pull(minage)` to `r participants%>%filter(species == "orangutan", sex == "f")%>%pull(maxage)`). The sample size at the different time points ranged from `r min(tpn$n)` to `r max(tpn$n)`.

Apes were housed at the Wolfgang KÃ¶hler Primate Research Center, located at Zoo Leipzig in Leipzig, Germany. Research was noninvasive and strictly adhered to the legal requirements in Germany. Animal husbandry and research complied with the European Association of Zoos and Aquaria Minimum Standards for the Accommodation and Care of Animals in Zoos and Aquaria as well as the World Association of Zoos and Aquariums Ethical Guidelines for the Conduct of Research on Animals by Zoos and Aquariums. Participation was voluntary, all food was given in addition to the daily diet, and water was available ad libitum throughout the study. The study was approved by an internal ethics committee at the Max Planck Institute for Evolutionary Anthropology.

## Design, Setup and Procedure

We tested apes on the same five tasks every other week. The tasks were always presented in the same order and with the same counterbalancing. Apes were tested in familiar sleeping or observation rooms by a single experimenter. Whenever possible, they were tested individually. For each individual, the tasks at one time point were usually spread out across two consecutive days with causality and inference on day 1 and quantity and switching on day 2. Gaze following trials were run at the beginning and the end of each day. The basic setup comprised a sliding table positioned in front of a clear Plexiglas panel. The experimenter sat on a small stool and used an occluder to cover the sliding table.

### Causality

Two identical cups with a lid were placed left and right on the table. The experimenter covered the table with the occluder, retrieved a piece of food and hid it in one the cups outside the view of the participant. Next, they removed the occluder, picked up the baited up and shook it three times, which produced a rattling sound. Next the cup was put back in place, the sliding table pushed forwards and the participant made a choice by pointing to one of the cups. If they picked the baited cup, there choice was coded as correct and they received the reward. On each time point, participants received 12 trials. 

### Inference by Exclusion

Inference trials were identical to causality trials but instead of shaking the baited cup, the experimenter shook the empty cup. On each time point, participants received 12 trials. Inference trials were intermixed with causality trials.

### Gaze Following

The experimenter sat opposite the ape and handed over food at a constant pace. That is, the experimenter picked up a piece of food, briefly held it out in front of her face and then handed it over to the participant. At some point, the experimenter looked up (i.e. moving her head up) while holding up the food in front of her head. After 10s, the experimenter looked down again and handed over the food. We coded whether the subject looked up during the 10s interval. Participants received a total of 8 trials, spread out across the two test days.    

### Quantity Discrimination

Two small plates were presented left and right on the table. The experimenter placed 5 small food pieces on one plate and 7 in the other. Then they pushed the sliding table forwards, and the subject made a choice. We coded as correct when the subject chose the plate with the larger quantity. There were 12 trials per time point.   

### Switching

Three different looking cups (silver cup with handle, plastic ice cone, red cup without handle) were placed next to each other on the table. There were two condition, in the place condition, the experimenter hid a piece of food under one of the cups in full view of the participant. Next, the cups were covered by the occluder and the experimenter switched the position of two cups, while the reward remained in the same location. We coded as correct, if the participant chose the location where the food was hidden. Participants received four trials in this condition. The feature condition, followed the same procedure but now the experimenter also moved the reward when switching the cups. A correct choice in this condition meant choosing the location that the cup was moved to. Here, participants received 8 trials. The dependent measure of interest for this task was calculated as: `[proportion correct place] - (1 - [proportion correct feature])`.  Positive values in this score mean that participants were quickly able to switch between choosing based on location to choosing based on feature. High negative values suggest that participants did not switch strategies.   

# Analysis and Results

We combined the data from all species for the analysis because sample sizes for some species were too small to get representative estimates. However, we accounted for the nesting of subjects in species as part of the random effect structure of our models. All analysis were run in `R`. Bayesian multilevel models were implemented using the package `brms` and used default priors.    

```{r}
# include metaanalytic estimate
time_plot_1 <- data_task%>%
  mutate(species = ifelse(grepl("chimp",group),"chimpanzee", group))%>%
  drop_na(performance)%>%
  mutate(time_point = factor(time_point))%>%
  group_by(task, time_point, species)%>%
  summarise(mean = mean(performance,na.rm = TRUE))

switch_data <- raw_data%>%
  filter(grepl("switch", task))%>%
  group_by(task, time_point)%>%
  tidyboot_mean(col = code, na.rm = TRUE)%>%
  mutate(phase = str_remove(task,"switching_"),
         task = "switching")

overview_plot <- data_task%>%
  mutate(species = ifelse(grepl("chimp",group),"chimpanzee", group))%>%
  mutate(time_point = factor(time_point))%>%
  group_by(task, performance)%>%
  mutate(n = n(),
         chance = ifelse(task == "switching", 1/3, ifelse(task == "gaze_following", NA,0.5)))%>%
  ungroup()

time_plot_2 <- data_task%>%
  mutate(species = ifelse(grepl("chimp",group),"chimpanzee", group))%>%
  drop_na(performance)%>%
  mutate(time_point = factor(time_point))%>%
  group_by(task, time_point)%>%
  tidyboot_mean(col = performance, na.rm = TRUE)

perf_plot <- ggplot()+
  facet_grid(~task)+
  geom_line(data = overview_plot, aes(x = time_point, y = performance, group = subject, size = n),col = "grey",alpha = .2)+
  geom_hline(data = overview_plot,aes(yintercept = chance), lty = 2, col = "black", alpha = .75)+
  geom_point(data = time_plot_1, aes(x = time_point, y = mean,  col = species), alpha = .6)+
  geom_line(data = time_plot_1, aes(x = time_point, y = mean, col = species, group = species), alpha = .6)+
  geom_pointrange(data = time_plot_2, aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper),pch = 4)+
  geom_line(data = time_plot_2, aes(x = time_point, y = mean, group = task))+
  theme_minimal()+
    geom_pointrange(data = switch_data, aes(x = time_point, y = mean, ymin = ci_lower, ymax = ci_upper, pch = phase), alpha = .5)+
    geom_line(data = switch_data, aes(x = time_point, y = mean, group = phase), alpha = .5)+
  theme_minimal(base_size = 8)+
  guides(size = F)+
  scale_shape(name = "Switching Phase")+
  scale_color_ptol(name = "Group")
```

```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=7, fig.height=2.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}
perf_plot
```

## Stability

First we looked at group level stability in performance. That is, we asked how much performance varied across time points in the different tasks. For this analysis, we ignored the temporal order of the different time points and treated them as replications of the same experiment (i.e. as a factor instead of a numerical variable). As such, we asked a meta-analytic question: how much variation is there between different instances of the same experiment. To answer this, we fitted a mixed model with a random intercept term for time point to the data from each task^[We modeled the trial by trial data using a binomial distribution in a logistic GLMM for all tasks, except switching. Here we modeled the score (by time point) as a truncated normal distribution]. As part of each model, we estimated a standard deviation of the random intercept term ($\tau$), which reflects the variation between time points. 

Figure XX visualizes performance across time points. The bottom row, gives the intercept estimate for the average effect across time points (with 95 % highest density interval (HDI)). For causality, inference and quantity, we can evaluate group level performance by comparing it to chance (50% correct = intercept of 0 in link space). Group level performance was reliably above chance for causality and quantity but at chance for quantity. For gaze following, there is no such reference level and we can simply say that at at least some individuals of all species followed the experimenter's gaze. The switching score was consistently negative, suggesting that - on a group level - apes did not switch strategies.    

Figure XX shows the posterior distribution of $\tau$ for each task. While performance was very stable for inference, quantity and switching ($\tau$ very close to 0), performance was slightly more variable for causality and varied substantially for gaze following. For causality, variation did not seem to follow a clear temporal pattern. On the other hand, for gaze following, there seems to be a downward trend with apes (as a group) becoming less likely to follow the experimenter's gaze. We explore this temporal pattern in more detail below. Taken together, we may say that 4 out of 5 measures yield stable measures of group level performance.

```{r}
bm_stab_data <- raw_data%>%
  mutate(trial_time_point = scale(trial_time_point),
         time_point = factor(time_point))%>%
  group_split(task, .keep = TRUE)%>%
  as.list()

# bm_stab <- brm_multiple(code ~  trial_time_point + (trial_time_point|group/subject) + (1|time_point),
#             family = bernoulli(),
#             data = bm_stab_data,
#             combine = F,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_stab,file = "saves/bm_stab.rds")

bm_stab <- readRDS(file = "saves/bm_stab.rds")

bm_stab_switch_data <- data_task%>%
  filter(task == "switching")%>%
  mutate(time_point = factor(time_point))%>%
  filter(!is.na(performance))

# bm_stab_switch <- brm(performance | trunc(lb=-1,ub=1) ~  1 + (1|group/subject) + (1|time_point),
#                       family = gaussian(),
#                       data = bm_stab_switch_data,
#                       control = list(adapt_delta = 0.99, max_treedepth = 20),
#                       iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_stab_switch,file = "saves/bm_stab_switch.rds")
# 
bm_stab_switch <- readRDS(file = "saves/bm_stab_switch.rds")

post_sample_task <- bind_rows(
posterior_samples(bm_stab[1], pars = c("b_Intercept","r_time_point.1.Intercept.","r_time_point.2.Intercept.","r_time_point.3.Intercept.","r_time_point.4.Intercept.","r_time_point.5.Intercept.","r_time_point.6.Intercept.","r_time_point.7.Intercept.","r_time_point.8.Intercept."))%>%
  gather(time_point, tp_int, -b_Intercept)%>%
  mutate(b_Intercept = tp_int + b_Intercept, 
         time_point = parse_number(str_remove(time_point,"\\.")))%>%mutate(task = "causality"),

posterior_samples(bm_stab[2], pars = c("b_Intercept","r_time_point.1.Intercept.","r_time_point.2.Intercept.","r_time_point.3.Intercept.","r_time_point.4.Intercept.","r_time_point.5.Intercept.","r_time_point.6.Intercept.","r_time_point.7.Intercept.","r_time_point.8.Intercept."))%>%
  gather(time_point, tp_int, -b_Intercept)%>%
  mutate(b_Intercept = tp_int + b_Intercept, 
         time_point = parse_number(str_remove(time_point,"\\.")))%>%mutate(task = "gaze_following"),

posterior_samples(bm_stab[3], pars = c("b_Intercept","r_time_point.1.Intercept.","r_time_point.2.Intercept.","r_time_point.3.Intercept.","r_time_point.4.Intercept.","r_time_point.5.Intercept.","r_time_point.6.Intercept.","r_time_point.7.Intercept.","r_time_point.8.Intercept."))%>%
  gather(time_point, tp_int, -b_Intercept)%>%
  mutate(b_Intercept = tp_int + b_Intercept, 
         time_point = parse_number(str_remove(time_point,"\\.")))%>%mutate(task = "inference"),

posterior_samples(bm_stab[4], pars = c("b_Intercept","r_time_point.1.Intercept.","r_time_point.2.Intercept.","r_time_point.3.Intercept.","r_time_point.4.Intercept.","r_time_point.5.Intercept.","r_time_point.6.Intercept.","r_time_point.7.Intercept.","r_time_point.8.Intercept."))%>%
  gather(time_point, tp_int, -b_Intercept)%>%
  mutate(b_Intercept = tp_int + b_Intercept, 
         time_point = parse_number(str_remove(time_point,"\\.")))%>%mutate(task = "quantity"),

posterior_samples(bm_stab_switch, pars = c("b_Intercept","r_time_point.1.Intercept.","r_time_point.2.Intercept.","r_time_point.3.Intercept.","r_time_point.4.Intercept.","r_time_point.5.Intercept.","r_time_point.6.Intercept.","r_time_point.7.Intercept.","r_time_point.8.Intercept."))%>%
  gather(time_point, tp_int, -b_Intercept)%>%
  mutate(b_Intercept = tp_int + b_Intercept, 
         time_point = parse_number(str_remove(time_point,"\\.")))%>%mutate(task = "switching")
)%>%
  group_by(task,time_point)%>%
  filter(!is.na(time_point))%>%
  mutate(mean = mean(b_Intercept),
         time_point = paste("Time point ", time_point, sep = ""))%>%
  mutate(time_point = factor(time_point))

pooled_effect_task <- bind_rows(
posterior_samples(bm_stab[1])%>%select(b_Intercept)%>%mutate(task = "causality", time_point = "Pooled Effect"),
posterior_samples(bm_stab[2])%>%select(b_Intercept)%>%mutate(task = "gaze_following", time_point = "Pooled Effect"),
posterior_samples(bm_stab[3])%>%select(b_Intercept)%>%mutate(task = "inference", time_point = "Pooled Effect"),
posterior_samples(bm_stab[4])%>%select(b_Intercept)%>%mutate(task = "quantity", time_point = "Pooled Effect"),
posterior_samples(bm_stab_switch)%>%select(b_Intercept)%>%mutate(task = "switching", time_point = "Pooled Effect")
)%>%
  mutate(time_point = factor(time_point))

forest_data_task <- bind_rows(post_sample_task, pooled_effect_task)%>%
  mutate(time_point = factor(time_point),
         measure = "Model Intercept")%>%
  filter(task != "switching_place")

forest_data_task_summary <- forest_data_task %>%
  group_by(task,measure, time_point) %>% 
  mean_hdci(b_Intercept)


## sd across tasks

sd_sample_task <- bind_rows(
  posterior_samples(bm_stab[1], pars = c("sd_time_point__Intercept"))%>%mutate(task = "causality")%>%
    mutate(tau_squared = sd_time_point__Intercept^2),
  posterior_samples(bm_stab[2], pars = c("sd_time_point__Intercept"))%>%mutate(task = "gaze_following")%>%
    mutate(tau_squared = sd_time_point__Intercept^2),
  posterior_samples(bm_stab[3], pars = c("sd_time_point__Intercept"))%>%mutate(task = "inference")%>%
    mutate(tau_squared = sd_time_point__Intercept^2),
  posterior_samples(bm_stab[4], pars = c("sd_time_point__Intercept"))%>%mutate(task = "quantity")%>%
    mutate(tau_squared = sd_time_point__Intercept^2),
  posterior_samples(bm_stab_switch, pars = c("sd_time_point__Intercept"))%>%mutate(task = "switching")%>%
    mutate(tau_squared = sd_time_point__Intercept^2)
)%>%
  mutate(time_point = "Tau")%>%
  filter(task != "switching_place")%>%
  mutate(time_point = factor(time_point),
         measure = "Heterogeneity")

sd_task_summary <- sd_sample_task %>%
  group_by(measure, time_point,task) %>% 
  mean_hdci(sd_time_point__Intercept,tau_squared)



meta_plot

ggplot(aes(b_Intercept, relevel(time_point, "Pooled Effect", after = Inf),fill = task), 
       data = forest_data_task) +
  facet_grid(measure~task, scales = "free",space = "free_y", shrink = T)+
  geom_vline(data = forest_data_task_summary%>%filter(time_point == "Pooled Effect"), aes(xintercept = b_Intercept), color = "grey", size = 1) +
  geom_vline(data = forest_data_task_summary%>%filter(time_point == "Pooled Effect"), aes(xintercept = .lower), color = "grey", linetype = 2) +
    geom_vline(data = forest_data_task_summary%>%filter(time_point == "Pooled Effect"), aes(xintercept = .upper), color = "grey", linetype = 2) +
  geom_segment(y = "Time point 1", yend = "Time point 1", x = -Inf, xend = Inf, color = "black", size = 1) +
  geom_vline(xintercept = 0, color = "black", size = .5, lty = 2) +
  geom_density_ridges(rel_min_height = 0.01,col = "black", scale = 3,
                      alpha = 0.5) +
  geom_text(data = mutate_if(sd_task_summary, is.numeric, round, 2),
    aes(label = glue("{sd_time_point__Intercept} [{sd_time_point__Intercept.lower}, {sd_time_point__Intercept.upper}]"), x= -Inf, y = time_point), hjust = "inward", size = 2)+
  geom_pointintervalh(data = forest_data_task_summary%>%filter(time_point == "Pooled Effect"), size = 1)+
  #geom_text(data = mutate_if(forest_data_task_summary%>%filter(time_point == "Pooled Effect"), is.numeric, round, 2), aes(label = glue("{b_Intercept} [{.lower}, {.upper}]"), x= Inf, y = time_point), hjust = "inward", size = 2)+
  geom_density_ridges(data = sd_sample_task, aes(sd_time_point__Intercept, time_point ,fill = task), rel_min_height = 0.01,col = "black", scale = .3, alpha = 0.5) +
  labs(x = element_blank(),
       y = element_blank()) +
  theme_minimal(base_size = 10)+
  guides(fill = F)+
  scale_fill_colorblind()
```


```{r 2-col-image3, fig.env = "figure*", fig.pos = "h", fig.width=7, fig.height=3, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}
meta_plot
```

## Reliability 

Next, we asked how stable performance is on an individual level. This question also relates to the reliability of each task - how well suited it is to capture differences between individuals. In general, reliability is high if individuals are consistently ranked across measurement instances. One way to assess reliability is to correlate performance from two time points (re-test reliability). Because we had multiple time points, we computed pairwise correlations for all combinations of time points (total of 28 unique correlations per task). This results in a distribution of correlations, which we visualize in Figure XX. Results suggest good re-test reliability for gaze following, causality and inference, variable reliability for quantity and poor reliability for switching. This pattern is interesting in light of the group level performance we reported above: stable performance on a group level does not imply stable individual differences. We come back to this point in the discussion. 

```{r}
cor_data <- data_task%>%
  drop_na(performance)%>%
  select(subject, task, time_point, performance)%>%
  pivot_wider(values_from = "performance", names_from = "time_point")%>%
  ungroup()%>%
  select(-subject)%>%
  group_by(task)%>%
  group_split(.keep = F)%>%
  setNames(unique(data_task$task))%>%
  purrr::map(cor_func)%>%
  melt()%>%
  mutate(task = L1)%>%
  select(task, value)

cor_data_sum <- cor_data%>%
  group_by(task)%>%
  mean_hdci(value)
  
# ggplot(cor_data, aes(x = value, col = task, fill = task))+
#   #geom_histogram(col = "black", fill = "white")+
#   geom_density(alpha = .3)+
#   #xlim(-0.5,1)+
#   #facet_wrap(~task)+
#   labs(x = "Correlation Coefficient", y = "")+
#   theme_minimal()+
#   scale_color_colorblind(name = "Task")+
#   scale_fill_colorblind(name = "Task")


rel_plot <- ggplot(data = cor_data, aes(x = value , y = task ,fill = task)) +
  geom_vline(xintercept = 0, color = "black", size = .5, lty = 2) +
  geom_density_ridges(rel_min_height = 0.01,col = "black", scale = 2,
                      alpha = 0.5) +
  geom_pointintervalh(data = cor_data_sum, size = 1)+
  labs(x = "Correlation Coefficient",
       y = element_blank()) +
  geom_text(data = mutate_if(cor_data_sum, is.numeric, round, 2),
    aes(label = glue("{value} [{.lower}, {.upper}]"), x= Inf), hjust = "inward", size = 2)+
  theme_minimal(base_size = 10)+
  xlim(-0.5,1.5)+
  guides(fill = F)+
  scale_fill_colorblind()
```

```{r plot, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=3.4, fig.height=2, fig.cap = "R plot" }

rel_plot

```

## Predictors

In the final set of analysis, we investigated if variation in cognitive performance could -- in part -- be explained by participant characteristics. We chose to look at variables that are commonly analyzed in the primate cognition literature: age, sex, rank and rearing history. Rank was rated by animal keepers at every time point and rearing history was classified as "mother reared", "human reared" and "unknown".

For each task, we ran the same five models^[We used the same response distributions as in the stability analysis.]: A baseline model predicting performance by time point (numerical) and trial as well as four models, each with one of the predictors (age, sex, rank and rearing history) added to the baseline model. We did not investigate any interaction models (interactions among the predictors or with time point) because we had no specific hypothesis in that direction. We used Bayesian model comparison based on WAIC (widely applicable information criterion) scores and weights [cite McElreath book]. This comparison tells us which of the models considered makes the best out-of-sample predictions. If the model with one predictor (e.g. age) would be consistently assigned the highest weight across tasks, we would conclude that cognitive performance is best predicted by participants' age.

Figure XX gives WAIC scores and weights for each model and task. Figure XX shows the posterior distribution of the test predictors (as well as for time point). The baseline model was ranked highest across tasks (first or second for all tasks), suggesting that none of the test predictors was consistently related to performance. Within the baseline model, the estimate for time point was close to 0 for all tasks except gaze following, for which it was largely negative (reflecting the downward trend we saw in Figure XX).

For gaze following, the model including sex as predictor was ranked highest: males were somewhat less likely to follow the experimenter's gaze. For quantity, the rank model was rated highest with lower ranking individuals showing better quantity discrimination.

Taken togther

```{r}
# bm_model_data <- raw_data%>%
#   filter(!is.na(rank) & !is.na(age) & !is.na(sex) & !is.na(rearing))%>%
#   mutate(trial_time_point = scale(trial_time_point),
#          time_point = scale(time_point),
#          rank = scale(rank),
#          age = scale(age))%>%
#   group_split(task, .keep = TRUE)%>%
#   as.list()
# 
#   
# bm_null <- brm_multiple(code ~ trial_time_point + time_point + (trial_time_point + time_point|group/subject),
#             family = bernoulli(),
#             data = bm_model_data,
#             combine = F,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_null,file = "saves/bm_null.rds")
# 
bm_null <- readRDS(file = "saves/bm_null.rds")
# 
# bm_rank <- brm_multiple(code ~ rank + trial_time_point + time_point + (trial_time_point + time_point|group/subject),
#             family = bernoulli(),
#             data = bm_model_data,
#             combine = F,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_rank,file = "saves/bm_rank.rds")
# 
bm_rank <- readRDS(file = "saves/bm_rank.rds")
# 
# bm_age <- brm_multiple(code ~ age + trial_time_point + time_point + (trial_time_point + time_point|group/subject),
#             family = bernoulli(),
#             data = bm_model_data,
#             combine = F,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_age,file = "saves/bm_age.rds")
# 
bm_age <- readRDS(file = "saves/bm_age.rds")
# 
# bm_sex <- brm_multiple(code ~ sex + trial_time_point + time_point + (trial_time_point + time_point|group/subject),
#             family = bernoulli(),
#             data = bm_model_data,
#             combine = F,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_sex,file = "saves/bm_sex.rds")
# 
bm_sex <- readRDS(file = "saves/bm_sex.rds")
# 
# bm_rearing <- brm_multiple(code ~ rearing + trial_time_point + time_point + (trial_time_point + time_point|group/subject),
#             family = bernoulli(),
#             data = bm_model_data,
#             combine = F,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_rearing,file = "saves/bm_rearing.rds")

bm_rearing <- readRDS(file = "saves/bm_rearing.rds")

## switching 

# bm_switch_data <- data_task%>%
#   filter(task == "switching")%>%
#   left_join(raw_data%>%filter(!is.na(rank))%>%group_by(subject,time_point,rank)%>%summarise(rank = mean(rank)))%>%
#   filter( !is.na(rank) & !is.na(age) & !is.na(sex) & !is.na(rearing) & !is.na(performance))%>%
#   mutate(time_point = scale(time_point),
#          rank = scale(rank),
#          age = scale(age))
# 
# bm_switch_null <- brm(performance | trunc(lb=-1,ub=1) ~  time_point + (time_point|group/subject),
#             family = gaussian(),
#             data = bm_switch_data,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
#saveRDS(bm_switch_null,file = "saves/bm_switch_null.rds")

bm_switch_null <- readRDS(file = "saves/bm_switch_null.rds")

# bm_switch_rank <- brm(performance | trunc(lb=-1,ub=1) ~  rank + time_point + (time_point|group/subject),
#             family = gaussian(),
#             data = bm_switch_data,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
#saveRDS(bm_switch_rank,file = "saves/bm_switch_rank.rds")

bm_switch_rank <- readRDS(file = "saves/bm_switch_rank.rds")

# bm_switch_sex <- brm(performance | trunc(lb=-1,ub=1) ~  sex + time_point + (time_point|group/subject),
#             family = gaussian(),
#             data = bm_switch_data,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_switch_sex,file = "saves/bm_switch_sex.rds")

bm_switch_sex <- readRDS(file = "saves/bm_switch_sex.rds")

# bm_switch_age <- brm(performance | trunc(lb=-1,ub=1) ~  age + time_point + (time_point|group/subject),
#             family = gaussian(),
#             data = bm_switch_data,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_switch_age,file = "saves/bm_switch_age.rds")

bm_switch_age <- readRDS(file = "saves/bm_switch_age.rds")

# bm_switch_rearing <- brm(performance | trunc(lb=-1,ub=1) ~  rearing + time_point + (time_point|group/subject),
#             family = gaussian(),
#             data = bm_switch_data,
#             control = list(adapt_delta = 0.99, max_treedepth = 20),
#             iter = 5000, cores = 3, chains = 3)
# 
# saveRDS(bm_switch_rearing,file = "saves/bm_switch_rearing.rds")

bm_switch_rearing <- readRDS(file = "saves/bm_switch_rearing.rds")
```


```{r}

# weights_caus <- model_weights(
#   bm_null%>%purrr::simplify() %>% pluck(1)%>%add_criterion(criterion = "waic"),
#   bm_rank%>%purrr::simplify() %>% pluck(1)%>%add_criterion(criterion = "waic"),
#   bm_age%>%purrr::simplify() %>% pluck(1)%>%add_criterion(criterion = "waic"),
#   bm_sex%>%purrr::simplify() %>% pluck(1)%>%add_criterion(criterion = "waic"),
#   bm_rearing%>%purrr::simplify() %>% pluck(1)%>%add_criterion(criterion = "waic"),
#   weights = "waic")%>%
#   as_tibble()%>%
#   dplyr::rename(weight = value)%>%
#   mutate(model = c("baseline","rank","age","sex","rearing"),
#          task = "causality")
# 
# 
# weights_gaze <- model_weights(
#   bm_null%>%purrr::simplify() %>% pluck(2)%>%add_criterion(criterion = "waic"),
#   bm_rank%>%purrr::simplify() %>% pluck(2)%>%add_criterion(criterion = "waic"),
#   bm_age%>%purrr::simplify() %>% pluck(2)%>%add_criterion(criterion = "waic"),
#   bm_sex%>%purrr::simplify() %>% pluck(2)%>%add_criterion(criterion = "waic"),
#   bm_rearing%>%purrr::simplify() %>% pluck(2)%>%add_criterion(criterion = "waic"),
#   weights = "waic")%>%
#   as_tibble()%>%
#   dplyr::rename(weight = value)%>%
#   mutate(model = c("baseline","rank","age","sex","rearing"),
#          task = "gaze_following")
# 
# 
# weights_inf <- model_weights(
#   bm_null%>%purrr::simplify() %>% pluck(3)%>%add_criterion(criterion = "waic"),
#   bm_rank%>%purrr::simplify() %>% pluck(3)%>%add_criterion(criterion = "waic"),
#   bm_age%>%purrr::simplify() %>% pluck(3)%>%add_criterion(criterion = "waic"),
#   bm_sex%>%purrr::simplify() %>% pluck(3)%>%add_criterion(criterion = "waic"),
#   bm_rearing%>%purrr::simplify() %>% pluck(3)%>%add_criterion(criterion = "waic"),
#   weights = "waic")%>%
#   as_tibble()%>%
#   dplyr::rename(weight = value)%>%
#   mutate(model = c("baseline","rank","age","sex","rearing"),
#          task = "inference")
# 
# weights_quant <- model_weights(
#   bm_null%>%purrr::simplify() %>% pluck(4)%>%add_criterion(criterion = "waic"),
#   bm_rank%>%purrr::simplify() %>% pluck(4)%>%add_criterion(criterion = "waic"),
#   bm_age%>%purrr::simplify() %>% pluck(4)%>%add_criterion(criterion = "waic"),
#   bm_sex%>%purrr::simplify() %>% pluck(4)%>%add_criterion(criterion = "waic"),
#   bm_rearing%>%purrr::simplify() %>% pluck(4)%>%add_criterion(criterion = "waic"),
#   weights = "waic")%>%
#   as_tibble()%>%
#   dplyr::rename(weight = value)%>%
#   mutate(model = c("baseline","rank","age","sex","rearing"),
#          task = "quantity")
# 
# weights_switch <- model_weights(
#   bm_switch_null%>%add_criterion(criterion = "waic"),
#   bm_switch_rank%>%add_criterion(criterion = "waic"),
#   bm_switch_age%>%add_criterion(criterion = "waic"),
#   bm_switch_sex%>%add_criterion(criterion = "waic"),
#   bm_switch_rearing%>%add_criterion(criterion = "waic"),
#   weights = "waic")%>%
#   as_tibble()%>%
#   dplyr::rename(weight = value)%>%
#   mutate(model = c("baseline","rank","age","sex","rearing"),
#          task = "switching")
# 
# 
# model_weights <- bind_rows(
#   weights_caus,
#   weights_gaze,
#   weights_inf,
#   weights_quant,
#   weights_switch
# )
# 
# saveRDS(model_weights, file = "saves/model_weights.rds")

model_weights <-  readRDS(file = "saves/model_weights.rds")
```



```{r}
# caus_waic <- bind_rows(
# 
#   as_tibble(waic(bm_null%>%purrr::simplify() %>% pluck(1))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "baseline", task = "causality"),
#     as_tibble(waic(bm_rank%>%purrr::simplify() %>% pluck(1))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rank", task = "causality"),
#     as_tibble(waic(bm_age%>%purrr::simplify() %>% pluck(1))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "age", task = "causality"),
#     as_tibble(waic(bm_sex%>%purrr::simplify() %>% pluck(1))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "sex", task = "causality"),
#     as_tibble(waic(bm_rearing%>%purrr::simplify() %>% pluck(1))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rearing", task = "causality")
# )
# 
# gaze_waic <- bind_rows(
# 
#   as_tibble(waic(bm_null%>%purrr::simplify() %>% pluck(2))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "baseline", task = "gaze_following"),
#     as_tibble(waic(bm_rank%>%purrr::simplify() %>% pluck(2))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rank", task = "gaze_following"),
#     as_tibble(waic(bm_age%>%purrr::simplify() %>% pluck(2))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "age", task = "gaze_following"),
#     as_tibble(waic(bm_sex%>%purrr::simplify() %>% pluck(2))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "sex", task = "gaze_following"),
#     as_tibble(waic(bm_rearing%>%purrr::simplify() %>% pluck(2))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rearing", task = "gaze_following")
# )
# 
# inf_waic <- bind_rows(
# 
#     as_tibble(waic(bm_null%>%purrr::simplify() %>% pluck(3))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "baseline", task = "inference"),
#     as_tibble(waic(bm_rank%>%purrr::simplify() %>% pluck(3))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rank", task = "inference"),
#     as_tibble(waic(bm_age%>%purrr::simplify() %>% pluck(3))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "age", task = "inference"),
#     as_tibble(waic(bm_sex%>%purrr::simplify() %>% pluck(3))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "sex", task = "inference"),
#     as_tibble(waic(bm_rearing%>%purrr::simplify() %>% pluck(3))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rearing", task = "inference")
# 
# )
# 
# quant_waic <- bind_rows(
# 
#       as_tibble(waic(bm_null%>%purrr::simplify() %>% pluck(4))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "baseline", task = "quantity"),
#     as_tibble(waic(bm_rank%>%purrr::simplify() %>% pluck(4))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rank", task = "quantity"),
#     as_tibble(waic(bm_age%>%purrr::simplify() %>% pluck(4))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "age", task = "quantity"),
#     as_tibble(waic(bm_sex%>%purrr::simplify() %>% pluck(4))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "sex", task = "quantity"),
#     as_tibble(waic(bm_rearing%>%purrr::simplify() %>% pluck(4))$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rearing", task = "quantity")
# 
# )
# 
# switch_waic <- bind_rows(
# 
#       as_tibble(waic(bm_switch_null)$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "baseline", task = "switching"),
#     as_tibble(waic(bm_switch_rank)$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rank", task = "switching"),
#     as_tibble(waic(bm_switch_age)$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "age", task = "switching"),
#     as_tibble(waic(bm_switch_sex)$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "sex", task = "switching"),
#     as_tibble(waic(bm_switch_rearing)$estimates, rownames = "measure")%>%filter(measure == "waic")%>%mutate(model = "rearing", task = "switching")
# 
# )
# 
# model_waic <- bind_rows(
#   caus_waic,
#   gaze_waic,
#   inf_waic,
#   quant_waic,
#   switch_waic
# )%>%
#   dplyr::rename(waic = Estimate,
#          se_waic = SE)%>%
#   select(-measure)
# 
# saveRDS(model_waic, file = "saves/model_waic.rds")

model_waic <-  readRDS(file = "saves/model_waic.rds")         
```

```{r}
model_comp <- model_waic %>%left_join(model_weights)

# comp_plot <- ggplot(data = model_comp, aes(fill=model, y=weight, x = task, label = paste(waic%>%round(digits =1), se_waic%>%round(digits =1), sep = "\n")))+
#   geom_bar(position="stack", stat="identity", width = .5, alpha = .8)+
#   geom_text(size = 2, position = position_stack(vjust = 0.5))+
#   labs(x = "", y = "WAIC Model Weights")+
#   scale_fill_ptol(name = "Predictor")+
#   theme_minimal()+
#   coord_flip()+
#   theme(legend.position = "right")
```

```{r xtable, results="asis"}
comp_tab <- model_comp%>%
  select(task, model, waic, se_waic, weight)%>%
  mutate_if(is.numeric, round, 2)%>%
  mutate(Task = c("Causality", rep("",4),"Gaze following", rep("",4),"Inference", rep("",4),"Quantity", rep("",4),"Switching", rep("",4)))%>%
  dplyr::rename(WAIC = waic,
                SE = se_waic, 
                Weight = weight,
                Model = model)%>%
  select(Task, Model, WAIC, SE, Weight)


tab1 <- xtable::xtable(comp_tab, 
                       caption = "This table prints across one column.")

print(tab1, type="latex", comment = F, table.placement = "H")
```

```{r}
sex_pred <- bind_rows(
posterior_samples(bm_sex[1], pars = "b_sexm")%>%mutate(task = "causality"),
posterior_samples(bm_sex[2], pars = "b_sexm")%>%mutate(task = "gaze_following"),
posterior_samples(bm_sex[3], pars = "b_sexm")%>%mutate(task = "inference"),
posterior_samples(bm_sex[4], pars = "b_sexm")%>%mutate(task = "quantity"),
posterior_samples(bm_switch_sex, pars = "b_sexm")%>%mutate(task = "switching")
)%>%
  dplyr::rename(value = b_sexm)%>%
  mutate(predictor = "sex (male)")


rank_pred <- bind_rows(
posterior_samples(bm_rank[1], pars = "b_rank")%>%mutate(task = "causality"),
posterior_samples(bm_rank[2], pars = "b_rank")%>%mutate(task = "gaze_following"),
posterior_samples(bm_rank[3], pars = "b_rank")%>%mutate(task = "inference"),
posterior_samples(bm_rank[4], pars = "b_rank")%>%mutate(task = "quantity"),
posterior_samples(bm_switch_rank, pars = "b_rank")%>%mutate(task = "switching")
)%>%
  dplyr::rename(value = b_rank)%>%
  mutate(predictor = "rank")

age_pred <- bind_rows(
posterior_samples(bm_age[1], pars = "b_age")%>%mutate(task = "causality"),
posterior_samples(bm_age[2], pars = "b_age")%>%mutate(task = "gaze_following"),
posterior_samples(bm_age[3], pars = "b_age")%>%mutate(task = "inference"),
posterior_samples(bm_age[4], pars = "b_age")%>%mutate(task = "quantity"),
posterior_samples(bm_switch_age, pars = "b_age")%>%mutate(task = "switching")
)%>%
  dplyr::rename(value = b_age)%>%
  mutate(predictor = "age")

time_pred <- bind_rows(
posterior_samples(bm_null[1], pars = "b_time_point")%>%mutate(task = "causality"),
posterior_samples(bm_null[2], pars = "b_time_point")%>%mutate(task = "gaze_following"),
posterior_samples(bm_null[3], pars = "b_time_point")%>%mutate(task = "inference"),
posterior_samples(bm_null[4], pars = "b_time_point")%>%mutate(task = "quantity"),
posterior_samples(bm_switch_null, pars = "b_time_point")%>%mutate(task = "switching")
)%>%
  dplyr::rename(value = b_time_point)%>%
  filter(value > -3)%>%
  mutate(predictor = "time_point")

pred <-  bind_rows(sex_pred,rank_pred,age_pred,time_pred)

pred_summary <- pred %>%
  group_by(task,predictor) %>% 
  mean_hdci(value)

pred_plot <-  ggplot(data = pred, aes(x = value , y = predictor ,fill = task)) +
  facet_grid(~task, scales = "free")+
  #geom_vline(data = forest.data.summary%>%filter(time_point == "Pooled Effect"), aes(xintercept = b_Intercept), color = "grey", size = 1) +
  #geom_vline(data = forest.data.summary%>%filter(time_point == "Pooled Effect"), aes(xintercept = .lower), color = "grey", linetype = 2) +
    #geom_vline(data = forest.data.summary%>%filter(time_point == "Pooled Effect"), aes(xintercept = .upper), color = "grey", linetype = 2) +
  #geom_segment(y = "Time point 1", yend = "Time point 1", x = -Inf, xend = Inf, color = "black", size = 0.5) +
  geom_vline(xintercept = 0, color = "black", size = .5, lty = 2) +
  geom_density_ridges(rel_min_height = 0.01,col = "black", scale = 1.5,
                      alpha = 0.5) +
  geom_pointintervalh(data = pred_summary, size = 1)+
  labs(x = "Model Estimate",
       y = element_blank()) +
  theme_minimal(base_size = 10)+
  guides(fill = F)+
  scale_fill_colorblind()



#ggsave(file = "predictors.png", width = 10, height = 3, scale = 1.5)
```

```{r 2-col-image2, fig.env = "figure*", fig.pos = "h", fig.width=7, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}
ggarrange(comp_plot,pred_plot, nrow = 2, ncol = 1, labels = c("A","B"))
```


# Discussion 

Reliability is independent from group level performance (leaving aside floor and ceiling effects); thus, a task may be highly reliable even if group level performance is at chance level [cite Hedge paper]. Here, we see such a pattern for inference. Group level performance is consistently at chance level for every time point. On a group level, one would conclude that great apes do not make the inference in question. However, the tasks is highly reliable, suggesting that accurately captures individual differences. Together with the observation that some individuals consistently perform at ceiling (see Figure XX), this suggests that the task is well suited to measure inferential abilities on a individual level. The opposite pattern holds for quantity. Here, group level performance is consistently above chance but individual differences are not very consistent, suggesting that variation is due to sources other than systematic differences between individuals. This Phenomenon is quite common in the adult cognitive literature (e.g. Hedge paper) and arises when experimental tasks (optimized for low variance in measurement) are used to study individual differences (requiring high variance in measurement). In sum, when planning to study individual differences by relating measures to one another, researchers are well advised to first study the reliability of these measures. Even though this takes considerable time and effort, it increases to the chances to find effects.  

Predictors: no predictor makes sense everywhere - carefully select them based on theoretical considerations. Avoid including them just to control for stuff (cite paper Mike Frank mentioned: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0152719)


# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
